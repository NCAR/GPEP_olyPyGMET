{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read study area basic information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/localuser/Github/PyGMET/auxiliary.py:13: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  data = np.genfromtxt(FileStnInfo, delimiter=',', dtype=None, skip_header=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read study area basic information\n"
     ]
    }
   ],
   "source": [
    "# prepare data for GMET probabilistic estimation based on OI merging and original station data\n",
    "import numpy as np\n",
    "import auxiliary as au\n",
    "from auxiliary_merge import m_DateList\n",
    "from calendar import monthrange\n",
    "import datetime as dt\n",
    "import netCDF4 as nc\n",
    "\n",
    "# control parameters\n",
    "year = 1983\n",
    "month = 12\n",
    "\n",
    "### Mac settings\n",
    "path_oi = '/Users/localuser/Research/EMDNA/oimerge'\n",
    "near_file_GMET = '/Users/localuser/Research/EMDNA/regression/weight_nearstn.npz'\n",
    "gmet_stndatafile = '/Users/localuser/Research/EMDNA/stndata_whole.npz'\n",
    "FileStnInfo = '/Users/localuser/Research/EMDNA/basicinfo/stnlist_whole.txt'  # station basic information (lists)\n",
    "FileGridInfo = '/Users/localuser/Research/EMDNA/basicinfo/gridinfo_whole.nc'  # study area information\n",
    "### Mac settings\n",
    "\n",
    "# ### Plato settings\n",
    "# path_oi = '/home/gut428/OImerge'\n",
    "# near_file_GMET = '/datastore/GLOBALWATER/CommonData/EMDNA/PyGMETout/weight.npz'\n",
    "# gmet_stndatafile = '/datastore/GLOBALWATER/CommonData/EMDNA/stndata_whole.npz'\n",
    "# FileStnInfo = '/datastore/GLOBALWATER/CommonData/EMDNA/StnGridInfo/stnlist_whole.txt'  # station basic information (lists)\n",
    "# FileGridInfo = '/datastore/GLOBALWATER/CommonData/EMDNA/StnGridInfo/gridinfo_whole.nc'  # study area information\n",
    "# ### Plato settings\n",
    "\n",
    "# output files\n",
    "FileRegression = '/home/gut428/GMET_regression' + '/reg_' + str(year*100+month) + '.nc'\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# 1. basic information\n",
    "\n",
    "print('Read study area basic information')\n",
    "# station location and attribute information\n",
    "# stninfo: [ stations, 1/lat/lon/elev/slope_ns/slope_we ]\n",
    "stnID, stninfo = au.readstnlist(FileStnInfo)\n",
    "nstn = len(stnID)\n",
    "\n",
    "date_cal_start = year * 10000 + month * 100 + 1\n",
    "date_cal_end = year * 10000 + month * 100 + monthrange(year, month)[1]\n",
    "\n",
    "date_cal_start2 = dt.datetime.strptime(str(date_cal_start), '%Y%m%d')\n",
    "date_cal_end2 = dt.datetime.strptime(str(date_cal_end), '%Y%m%d')\n",
    "ntimes = (date_cal_end2 - date_cal_start2).days + 1  # time steps to be processed\n",
    "\n",
    "# seconds since 1970-1-1 0:0:0\n",
    "daydiff = (date_cal_start2 - dt.datetime(1970, 1, 1)).days\n",
    "seconds = (np.arange(ntimes) + daydiff) * 86400\n",
    "\n",
    "# datelist: yyyymmdd\n",
    "yyyymmdd = np.zeros(ntimes, dtype=int)\n",
    "for d in range(ntimes):\n",
    "    dated = date_cal_start2 + dt.timedelta(days=d)\n",
    "    yyyymmdd[d] = int(dated.strftime(\"%Y%m%d\"))\n",
    "yyyymm = np.floor(yyyymmdd / 100).astype(int)\n",
    "mm = np.floor(np.mod(yyyymmdd, 10000) / 100).astype(int)\n",
    "\n",
    "# grid information\n",
    "lontar = np.arange(-180 + 0.05, -50, 0.1)\n",
    "lattar = np.arange(85 - 0.05, 5, -0.1)\n",
    "nrows = len(lattar)\n",
    "ncols = len(lontar)\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# 2. read study area basic information\n",
    "print('Read study area basic information')\n",
    "ncfid = nc.Dataset(FileGridInfo)\n",
    "gridlat = ncfid.variables['latitude'][:].data\n",
    "gridlon = ncfid.variables['longitude'][:].data\n",
    "gridele = ncfid.variables['elev'][:].data\n",
    "gridgns = ncfid.variables['gradient_n_s'][:].data\n",
    "gridgwe = ncfid.variables['gradient_w_e'][:].data\n",
    "mask = ncfid.variables['mask'][:].data  # 1: grids to be considered; the other values: invalid grids\n",
    "ncfid.close()\n",
    "\n",
    "gridinfo = np.zeros([nrows, ncols, 6])\n",
    "gridinfo[:, :, 0] = 1\n",
    "gridinfo[:, :, 1] = gridlat\n",
    "gridinfo[:, :, 2] = gridlon\n",
    "gridinfo[:, :, 3] = gridele\n",
    "gridinfo[:, :, 4] = gridgns\n",
    "gridinfo[:, :, 5] = gridgwe\n",
    "del gridlat, gridlon, gridele, gridgns, gridgwe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load near station information\n",
    "datatemp = np.load(near_file_GMET)\n",
    "near_loc_grid = datatemp['near_grid_prcpLoc']\n",
    "near_weight_grid = datatemp['near_grid_prcpWeight']\n",
    "near_dist_grid = datatemp['near_grid_prcpDist']\n",
    "near_loc_grid = np.flipud(near_loc_grid)\n",
    "near_weight_grid = np.flipud(near_weight_grid)\n",
    "near_dist_grid = np.flipud(near_dist_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derive y_max for each grid pixels\n",
    "\n",
    "# load station data\n",
    "date_list, date_number = m_DateList(1979, 2018, 'ByYear')\n",
    "indym = (date_number['yyyy'] == year) & (date_number['mm'] == month)\n",
    "datatemp = np.load(gmet_stndatafile)\n",
    "stndata = datatemp['prcp_stn'][:, indym]\n",
    "stnlle = datatemp['stn_lle']\n",
    "nstn, ntimes = np.shape(stndata)\n",
    "del datatemp\n",
    "\n",
    "y_max = np.nan * np.zeros([nrows, ncols, ntimes], dtype=np.float32)\n",
    "for r in range(nrows):\n",
    "    for c in range(ncols):\n",
    "        if near_loc_grid[r, c, 0] < 0:\n",
    "            continue\n",
    "        nearloci = near_loc_grid[r, c, :]\n",
    "        nearloci = nearloci[nearloci > -1]\n",
    "        y_max[r, c, :] = np.nanmax(stndata[nearloci, :], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tmean lag-1 daily autocorrelation:  0.7110968015136039\n",
      "Trange-prcp daily correlation:  -0.12028391002639842\n"
     ]
    }
   ],
   "source": [
    "# calculate auto_corr and t_p_corr\n",
    "windows = 1  # parameters for auto-cc t-p-cc calculation: 1 could be better than 31\n",
    "lag = 1\n",
    "datatemp = np.load(gmet_stndatafile)\n",
    "stndata = datatemp['prcp_stn'][:, indym]\n",
    "mean_autocorr, mean_tp_corr = \\\n",
    "    au.cc_calculate(windows, lag, datatemp['prcp_stn'][:, indym],\n",
    "                    datatemp['tmean_stn'][:, indym], datatemp['trange_stn'][:, indym])\n",
    "print('Tmean lag-1 daily autocorrelation: ', mean_autocorr)\n",
    "print('Trange-prcp daily correlation: ', mean_tp_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load OI-merged pop, pcp, tmean, trange\n",
    "# fileoi = path_oi + '/oimerge_pop' + str(year * 100 + month) + '.npz'\n",
    "# datatemp = np.load(fileoi)\n",
    "# pop = datatemp['oi_value']\n",
    "# # pop_err = datatemp['oi_error']\n",
    "filepop = '/Users/localuser/Research/EMDNA/pop/bmamerge_pop_198312.npz'\n",
    "datatemp=np.load(filepop)\n",
    "pop=datatemp['bma_data']\n",
    "\n",
    "fileoi = path_oi + '/oimerge_prcp' + str(year * 100 + month) + '_boxcox.npz'\n",
    "datatemp = np.load(fileoi)\n",
    "prcp = datatemp['oi_value']  # value in normal space\n",
    "prcp_err = datatemp['oi_error']\n",
    "\n",
    "fileoi = path_oi + '/oimerge_tmean' + str(year * 100 + month) + '.npz'\n",
    "datatemp = np.load(fileoi)\n",
    "tmean = datatemp['oi_value']\n",
    "tmean_err = datatemp['oi_error']\n",
    "\n",
    "fileoi = path_oi + '/oimerge_trange' + str(year * 100 + month) + '.npz'\n",
    "datatemp = np.load(fileoi)\n",
    "trange = datatemp['oi_value']\n",
    "trange_err = datatemp['oi_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_max = np.flipud(y_max)\n",
    "pop = np.flipud(pop)\n",
    "prcp = np.flipud(prcp)\n",
    "prcp_err = np.flipud(prcp_err)\n",
    "tmean = np.flipud(tmean)\n",
    "tmean_err = np.flipud(tmean_err)\n",
    "trange = np.flipud(trange)\n",
    "trange_err = np.flipud(trange_err)\n",
    "au.save_output_nc('test_input.nc', gridinfo, seconds, mean_autocorr, mean_tp_corr, pop, prcp, tmean, trange,\n",
    "                  prcp_err, tmean_err, trange_err, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GS71872099999'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stnID[24180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
