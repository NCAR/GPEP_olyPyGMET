{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read study area basic information\n",
      "Read study area basic information\n",
      "Read station precipitation and temperature data\n",
      "FileStnData exists. loading ...\n",
      "Calculate correlation (auto_cc and t_p_cc)\n",
      "Tmean lag-1 daily autocorrelation:  0.9992785833751292\n",
      "Trange-prcp daily correlation:  -0.08397315807792646\n",
      "FileWeight exists. loading ...\n",
      "Estimate daily regression error at station points\n",
      "Current time: 0 Total times: 365\n",
      "Current time: 1 Total times: 365\n",
      "Current time: 2 Total times: 365\n",
      "Current time: 3 Total times: 365\n",
      "Current time: 4 Total times: 365\n",
      "Current time: 5 Total times: 365\n",
      "Current time: 6 Total times: 365\n",
      "Current time: 7 Total times: 365\n",
      "Current time: 8 Total times: 365\n",
      "Current time: 9 Total times: 365\n",
      "Current time: 10 Total times: 365\n",
      "Current time: 11 Total times: 365\n",
      "Current time: 12 Total times: 365\n",
      "Current time: 13 Total times: 365\n",
      "Current time: 14 Total times: 365\n",
      "Current time: 15 Total times: 365\n",
      "Current time: 16 Total times: 365\n",
      "Current time: 17 Total times: 365\n",
      "Current time: 18 Total times: 365\n",
      "Current time: 19 Total times: 365\n",
      "Current time: 20 Total times: 365\n",
      "Current time: 21 Total times: 365\n",
      "Current time: 22 Total times: 365\n",
      "Current time: 23 Total times: 365\n",
      "Current time: 24 Total times: 365\n",
      "Current time: 25 Total times: 365\n",
      "Current time: 26 Total times: 365\n",
      "Current time: 27 Total times: 365\n",
      "Current time: 28 Total times: 365\n",
      "Current time: 29 Total times: 365\n",
      "Current time: 30 Total times: 365\n",
      "Current time: 31 Total times: 365\n",
      "Current time: 32 Total times: 365\n",
      "Current time: 33 Total times: 365\n",
      "Current time: 34 Total times: 365\n",
      "Current time: 35 Total times: 365\n",
      "Current time: 36 Total times: 365\n",
      "Current time: 37 Total times: 365\n",
      "Current time: 38 Total times: 365\n",
      "Current time: 39 Total times: 365\n",
      "Current time: 40 Total times: 365\n",
      "Current time: 41 Total times: 365\n",
      "Current time: 42 Total times: 365\n",
      "Current time: 43 Total times: 365\n",
      "Current time: 44 Total times: 365\n",
      "Current time: 45 Total times: 365\n",
      "Current time: 46 Total times: 365\n",
      "Current time: 47 Total times: 365\n",
      "Current time: 48 Total times: 365\n",
      "Current time: 49 Total times: 365\n",
      "Current time: 50 Total times: 365\n",
      "Current time: 51 Total times: 365\n",
      "Current time: 52 Total times: 365\n",
      "Current time: 53 Total times: 365\n",
      "Current time: 54 Total times: 365\n",
      "Current time: 55 Total times: 365\n",
      "Current time: 56 Total times: 365\n",
      "Current time: 57 Total times: 365\n",
      "Current time: 58 Total times: 365\n",
      "Current time: 59 Total times: 365\n",
      "Current time: 60 Total times: 365\n",
      "Current time: 61 Total times: 365\n",
      "Current time: 62 Total times: 365\n",
      "Current time: 63 Total times: 365\n",
      "Current time: 64 Total times: 365\n",
      "Current time: 65 Total times: 365\n",
      "Current time: 66 Total times: 365\n",
      "Current time: 67 Total times: 365\n",
      "Current time: 68 Total times: 365\n",
      "Current time: 69 Total times: 365\n",
      "Current time: 70 Total times: 365\n",
      "Current time: 71 Total times: 365\n",
      "Current time: 72 Total times: 365\n",
      "Current time: 73 Total times: 365\n",
      "Current time: 74 Total times: 365\n",
      "Current time: 75 Total times: 365\n",
      "Current time: 76 Total times: 365\n",
      "Current time: 77 Total times: 365\n",
      "Current time: 78 Total times: 365\n",
      "Current time: 79 Total times: 365\n",
      "Current time: 80 Total times: 365\n",
      "Current time: 81 Total times: 365\n",
      "Current time: 82 Total times: 365\n",
      "Current time: 83 Total times: 365\n",
      "Current time: 84 Total times: 365\n",
      "Current time: 85 Total times: 365\n",
      "Current time: 86 Total times: 365\n",
      "Current time: 87 Total times: 365\n",
      "Current time: 88 Total times: 365\n",
      "Current time: 89 Total times: 365\n",
      "Current time: 90 Total times: 365\n",
      "Current time: 91 Total times: 365\n",
      "Current time: 92 Total times: 365\n",
      "Current time: 93 Total times: 365\n",
      "Current time: 94 Total times: 365\n",
      "Current time: 95 Total times: 365\n",
      "Current time: 96 Total times: 365\n",
      "Current time: 97 Total times: 365\n",
      "Current time: 98 Total times: 365\n",
      "Current time: 99 Total times: 365\n",
      "Current time: 100 Total times: 365\n",
      "Current time: 101 Total times: 365\n",
      "Current time: 102 Total times: 365\n",
      "Current time: 103 Total times: 365\n",
      "Current time: 104 Total times: 365\n",
      "Current time: 105 Total times: 365\n",
      "Current time: 106 Total times: 365\n",
      "Current time: 107 Total times: 365\n",
      "Current time: 108 Total times: 365\n",
      "Current time: 109 Total times: 365\n",
      "Current time: 110 Total times: 365\n",
      "Current time: 111 Total times: 365\n",
      "Current time: 112 Total times: 365\n",
      "Current time: 113 Total times: 365\n",
      "Current time: 114 Total times: 365\n",
      "Current time: 115 Total times: 365\n",
      "Current time: 116 Total times: 365\n",
      "Current time: 117 Total times: 365\n",
      "Current time: 118 Total times: 365\n",
      "Current time: 119 Total times: 365\n",
      "Current time: 120 Total times: 365\n",
      "Current time: 121 Total times: 365\n",
      "Current time: 122 Total times: 365\n",
      "Current time: 123 Total times: 365\n",
      "Current time: 124 Total times: 365\n",
      "Current time: 125 Total times: 365\n",
      "Current time: 126 Total times: 365\n",
      "Current time: 127 Total times: 365\n",
      "Current time: 128 Total times: 365\n",
      "Current time: 129 Total times: 365\n",
      "Current time: 130 Total times: 365\n",
      "Current time: 131 Total times: 365\n",
      "Current time: 132 Total times: 365\n",
      "Current time: 133 Total times: 365\n",
      "Current time: 134 Total times: 365\n",
      "Current time: 135 Total times: 365\n",
      "Current time: 136 Total times: 365\n",
      "Current time: 137 Total times: 365\n",
      "Current time: 138 Total times: 365\n",
      "Current time: 139 Total times: 365\n",
      "Current time: 140 Total times: 365\n",
      "Current time: 141 Total times: 365\n",
      "Current time: 142 Total times: 365\n",
      "Current time: 143 Total times: 365\n",
      "Current time: 144 Total times: 365\n",
      "Current time: 145 Total times: 365\n",
      "Current time: 146 Total times: 365\n",
      "Current time: 147 Total times: 365\n",
      "Current time: 148 Total times: 365\n",
      "Current time: 149 Total times: 365\n",
      "Current time: 150 Total times: 365\n",
      "Current time: 151 Total times: 365\n",
      "Current time: 152 Total times: 365\n",
      "Current time: 153 Total times: 365\n",
      "Current time: 154 Total times: 365\n",
      "Current time: 155 Total times: 365\n",
      "Current time: 156 Total times: 365\n",
      "Current time: 157 Total times: 365\n",
      "Current time: 158 Total times: 365\n",
      "Current time: 159 Total times: 365\n",
      "Current time: 160 Total times: 365\n",
      "Current time: 161 Total times: 365\n",
      "Current time: 162 Total times: 365\n",
      "Current time: 163 Total times: 365\n",
      "Current time: 164 Total times: 365\n",
      "Current time: 165 Total times: 365\n",
      "Current time: 166 Total times: 365\n",
      "Current time: 167 Total times: 365\n",
      "Current time: 168 Total times: 365\n",
      "Current time: 169 Total times: 365\n",
      "Current time: 170 Total times: 365\n",
      "Current time: 171 Total times: 365\n",
      "Current time: 172 Total times: 365\n",
      "Current time: 173 Total times: 365\n",
      "Current time: 174 Total times: 365\n",
      "Current time: 175 Total times: 365\n",
      "Current time: 176 Total times: 365\n",
      "Current time: 177 Total times: 365\n",
      "Current time: 178 Total times: 365\n",
      "Current time: 179 Total times: 365\n",
      "Current time: 180 Total times: 365\n",
      "Current time: 181 Total times: 365\n",
      "Current time: 182 Total times: 365\n",
      "Current time: 183 Total times: 365\n",
      "Current time: 184 Total times: 365\n",
      "Current time: 185 Total times: 365\n",
      "Current time: 186 Total times: 365\n",
      "Current time: 187 Total times: 365\n",
      "Current time: 188 Total times: 365\n",
      "Current time: 189 Total times: 365\n",
      "Current time: 190 Total times: 365\n",
      "Current time: 191 Total times: 365\n",
      "Current time: 192 Total times: 365\n",
      "Current time: 193 Total times: 365\n",
      "Current time: 194 Total times: 365\n",
      "Current time: 195 Total times: 365\n",
      "Current time: 196 Total times: 365\n",
      "Current time: 197 Total times: 365\n",
      "Current time: 198 Total times: 365\n",
      "Current time: 199 Total times: 365\n",
      "Current time: 200 Total times: 365\n",
      "Current time: 201 Total times: 365\n",
      "Current time: 202 Total times: 365\n",
      "Current time: 203 Total times: 365\n",
      "Current time: 204 Total times: 365\n",
      "Current time: 205 Total times: 365\n",
      "Current time: 206 Total times: 365\n",
      "Current time: 207 Total times: 365\n",
      "Current time: 208 Total times: 365\n",
      "Current time: 209 Total times: 365\n",
      "Current time: 210 Total times: 365\n",
      "Current time: 211 Total times: 365\n",
      "Current time: 212 Total times: 365\n",
      "Current time: 213 Total times: 365\n",
      "Current time: 214 Total times: 365\n",
      "Current time: 215 Total times: 365\n",
      "Current time: 216 Total times: 365\n",
      "Current time: 217 Total times: 365\n",
      "Current time: 218 Total times: 365\n",
      "Current time: 219 Total times: 365\n",
      "Current time: 220 Total times: 365\n",
      "Current time: 221 Total times: 365\n",
      "Current time: 222 Total times: 365\n",
      "Current time: 223 Total times: 365\n",
      "Current time: 224 Total times: 365\n",
      "Current time: 225 Total times: 365\n",
      "Current time: 226 Total times: 365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time: 227 Total times: 365\n",
      "Current time: 228 Total times: 365\n",
      "Current time: 229 Total times: 365\n",
      "Current time: 230 Total times: 365\n",
      "Current time: 231 Total times: 365\n",
      "Current time: 232 Total times: 365\n",
      "Current time: 233 Total times: 365\n",
      "Current time: 234 Total times: 365\n",
      "Current time: 235 Total times: 365\n",
      "Current time: 236 Total times: 365\n",
      "Current time: 237 Total times: 365\n",
      "Current time: 238 Total times: 365\n",
      "Current time: 239 Total times: 365\n",
      "Current time: 240 Total times: 365\n",
      "Current time: 241 Total times: 365\n",
      "Current time: 242 Total times: 365\n",
      "Current time: 243 Total times: 365\n",
      "Current time: 244 Total times: 365\n",
      "Current time: 245 Total times: 365\n",
      "Current time: 246 Total times: 365\n",
      "Current time: 247 Total times: 365\n",
      "Current time: 248 Total times: 365\n",
      "Current time: 249 Total times: 365\n",
      "Current time: 250 Total times: 365\n",
      "Current time: 251 Total times: 365\n",
      "Current time: 252 Total times: 365\n",
      "Current time: 253 Total times: 365\n",
      "Current time: 254 Total times: 365\n",
      "Current time: 255 Total times: 365\n",
      "Current time: 256 Total times: 365\n",
      "Current time: 257 Total times: 365\n",
      "Current time: 258 Total times: 365\n",
      "Current time: 259 Total times: 365\n",
      "Current time: 260 Total times: 365\n",
      "Current time: 261 Total times: 365\n",
      "Current time: 262 Total times: 365\n",
      "Current time: 263 Total times: 365\n",
      "Current time: 264 Total times: 365\n",
      "Current time: 265 Total times: 365\n",
      "Current time: 266 Total times: 365\n",
      "Current time: 267 Total times: 365\n",
      "Current time: 268 Total times: 365\n",
      "Current time: 269 Total times: 365\n",
      "Current time: 270 Total times: 365\n",
      "Current time: 271 Total times: 365\n",
      "Current time: 272 Total times: 365\n",
      "Current time: 273 Total times: 365\n",
      "Current time: 274 Total times: 365\n",
      "Current time: 275 Total times: 365\n",
      "Current time: 276 Total times: 365\n",
      "Current time: 277 Total times: 365\n",
      "Current time: 278 Total times: 365\n",
      "Current time: 279 Total times: 365\n",
      "Current time: 280 Total times: 365\n",
      "Current time: 281 Total times: 365\n",
      "Current time: 282 Total times: 365\n",
      "Current time: 283 Total times: 365\n",
      "Current time: 284 Total times: 365\n",
      "Current time: 285 Total times: 365\n",
      "Current time: 286 Total times: 365\n",
      "Current time: 287 Total times: 365\n",
      "Current time: 288 Total times: 365\n",
      "Current time: 289 Total times: 365\n",
      "Current time: 290 Total times: 365\n",
      "Current time: 291 Total times: 365\n",
      "Current time: 292 Total times: 365\n",
      "Current time: 293 Total times: 365\n",
      "Current time: 294 Total times: 365\n",
      "Current time: 295 Total times: 365\n",
      "Current time: 296 Total times: 365\n",
      "Current time: 297 Total times: 365\n",
      "Current time: 298 Total times: 365\n",
      "Current time: 299 Total times: 365\n",
      "Current time: 300 Total times: 365\n",
      "Current time: 301 Total times: 365\n",
      "Current time: 302 Total times: 365\n",
      "Current time: 303 Total times: 365\n",
      "Current time: 304 Total times: 365\n",
      "Current time: 305 Total times: 365\n",
      "Current time: 306 Total times: 365\n",
      "Current time: 307 Total times: 365\n",
      "Current time: 308 Total times: 365\n",
      "Current time: 309 Total times: 365\n",
      "Current time: 310 Total times: 365\n",
      "Current time: 311 Total times: 365\n",
      "Current time: 312 Total times: 365\n",
      "Current time: 313 Total times: 365\n",
      "Current time: 314 Total times: 365\n",
      "Current time: 315 Total times: 365\n",
      "Current time: 316 Total times: 365\n",
      "Current time: 317 Total times: 365\n",
      "Current time: 318 Total times: 365\n",
      "Current time: 319 Total times: 365\n",
      "Current time: 320 Total times: 365\n",
      "Current time: 321 Total times: 365\n",
      "Current time: 322 Total times: 365\n",
      "Current time: 323 Total times: 365\n",
      "Current time: 324 Total times: 365\n",
      "Current time: 325 Total times: 365\n",
      "Current time: 326 Total times: 365\n",
      "Current time: 327 Total times: 365\n",
      "Current time: 328 Total times: 365\n",
      "Current time: 329 Total times: 365\n",
      "Current time: 330 Total times: 365\n",
      "Current time: 331 Total times: 365\n",
      "Current time: 332 Total times: 365\n",
      "Current time: 333 Total times: 365\n",
      "Current time: 334 Total times: 365\n",
      "Current time: 335 Total times: 365\n",
      "Current time: 336 Total times: 365\n",
      "Current time: 337 Total times: 365\n",
      "Current time: 338 Total times: 365\n",
      "Current time: 339 Total times: 365\n",
      "Current time: 340 Total times: 365\n",
      "Current time: 341 Total times: 365\n",
      "Current time: 342 Total times: 365\n",
      "Current time: 343 Total times: 365\n",
      "Current time: 344 Total times: 365\n",
      "Current time: 345 Total times: 365\n",
      "Current time: 346 Total times: 365\n",
      "Current time: 347 Total times: 365\n",
      "Current time: 348 Total times: 365\n",
      "Current time: 349 Total times: 365\n",
      "Current time: 350 Total times: 365\n",
      "Current time: 351 Total times: 365\n",
      "Current time: 352 Total times: 365\n",
      "Current time: 353 Total times: 365\n",
      "Current time: 354 Total times: 365\n",
      "Current time: 355 Total times: 365\n",
      "Current time: 356 Total times: 365\n",
      "Current time: 357 Total times: 365\n",
      "Current time: 358 Total times: 365\n",
      "Current time: 359 Total times: 365\n",
      "Current time: 360 Total times: 365\n",
      "Current time: 361 Total times: 365\n",
      "Current time: 362 Total times: 365\n",
      "Current time: 363 Total times: 365\n",
      "Current time: 364 Total times: 365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/localuser/Github/PyGMET/auxiliary.py:92: RuntimeWarning: invalid value encountered in less\n",
      "  data[data < -3] = -3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.52814163, 0.78415471, 1.01388001, 0.64433151])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import auxiliary as au\n",
    "import regression as reg\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import io\n",
    "import os\n",
    "import sys\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "########################################################################################################################\n",
    "# 0. read/define configuration information\n",
    "# setting: file and path names of inputs\n",
    "# FileStnInfo = '/Users/localuser/GMET/Example_tgq/inputs/stnlist_example.txt'  # station basic information (lists)\n",
    "# FileGridInfo = '/Users/localuser/GMET/Example_tgq/inputs/gridinfo_example.nc'  # study area information\n",
    "# PathStn = '/Users/localuser/GMET/Example_tgq/StnDaily_train'  # original station data (prcp ...)\n",
    "FileStnInfo = '/Users/localuser/GMET/pyGMET_NA/stnlist_whole.txt'  # station basic information (lists)\n",
    "FileGridInfo = '/Users/localuser/GMET/pyGMET_NA/gridinfo_whole.nc'  # study area information\n",
    "PathStn = '/Users/localuser/GMET/StnInput_daily'\n",
    "# FileStnInfo = '/Users/localuser/GMET/Example/inputs/stnlist_slope.w_subset.txt'  # station basic information (lists)\n",
    "# FileGridInfo = '/Users/localuser/GMET/Example/inputs/gridinfo.0625.w_subset.nc'  # study area information\n",
    "# PathStn = '/Users/localuser/GMET/Example/stndata'\n",
    "\n",
    "# setting: start and end date\n",
    "# calculation start/end date:\n",
    "date_cal_start = 20180101  # yyyymmdd: start date\n",
    "date_cal_end = 20181231  # yyyymmdd: end date\n",
    "# station data (in PathStn) start/end date:\n",
    "date_stn_start = 19790101  # yyyymmdd: start date\n",
    "date_stn_end = 20181231  # yyyymmdd: end date\n",
    "\n",
    "# setting: paramters for lag correlation of tmean_stn_daily, and cross-correlation between prcp and trange_stn_daily\n",
    "windows = 31  # parameters for auto-cc t-p-cc calculation: 1 could be better than 31\n",
    "lag = 1\n",
    "\n",
    "# setting: searching nearby stations\n",
    "nearstn_min = 20  # nearby stations: minimum number\n",
    "nearstn_max = 30  # nearby stations: maximum number\n",
    "search_radius = 1000  # km. only search stations within this radius even nearstn_max cannot be reached\n",
    "max_dist = 100  # max_distance in distance-based weight calculation\n",
    "\n",
    "# note: if cai_mode = 0, all *_climo and *_anom files won't work.\n",
    "# setting: parameters for transforming temp to approximate normal distribution\n",
    "trans_mode = 'box-cox'  # box-cox or power-law or none\n",
    "trans_exp_daily = 4\n",
    "\n",
    "# setting: overwrite flags. -1:don't save files; 0: don't overwrite files; 1 is to overwrite existing files;\n",
    "ow_daily = 0\n",
    "ow_weight = 0\n",
    "ow_stn = 0\n",
    "\n",
    "# setting: output files\n",
    "FileStnData = '/Users/localuser/GMET/pyGMET_NA/station_data.npz'\n",
    "FileWeight = '/Users/localuser/GMET/pyGMET_NA/weight_nearstn.npz'\n",
    "FileRegError_daily = '/Users/localuser/GMET/pyGMET_NA/regress_daily_error_boxcox.npz'  # regression error at station points\n",
    "FileRegression_daily = '/Users/localuser/GMET/pyGMET_NA/regress_daily_output.npz'\n",
    "# FileStnData = '/Users/localuser/GMET/pyGMET_NA/station_data.npz'\n",
    "# FileWeight = '/Users/localuser/GMET/pyGMET_NA/weight_nearstn.npz'\n",
    "# FileRegError_daily = '/Users/localuser/GMET/pyGMET_NA/regress_daily_error.npz'  # regression error at station points\n",
    "# FileRegression_daily = '/Users/localuser/GMET/pyGMET_NA/regress_daily_output.npz'\n",
    "\n",
    "# setting: climatologically aided interpolation (CAI)\n",
    "# CAI mode is not mature for now\n",
    "cai_mode = 0  # 0: don't use CAI; 1: for each month; 2: calculate climatology using all months during the period\n",
    "daily_flag = 1  # if cai_mode >0, then if daily_flag=1, do daily regression, else, do not do daily regression\n",
    "ow_climo = 0\n",
    "ow_anom = 0\n",
    "trans_exp_anom = 3  # following fortran version. But I think if negative value occurs, just assign zero anomaly prcp\n",
    "trans_exp_climo = 4\n",
    "FileRegError_climo = '/Users/localuser/GMET/pyGMET_NA/regress_climo_error.npz'\n",
    "FileRegression_climo = '/Users/localuser/GMET/pyGMET_NA/regress_climo_output.npz'\n",
    "FileRegError_anom = '/Users/localuser/GMET/pyGMET_NA/regress_anom_error.npz'\n",
    "FileRegression_anom = '/Users/localuser/GMET/pyGMET_NA/regress_anom_output.npz'\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# check file status\n",
    "# this part should be activated in operational application\n",
    "# if os.path.isfile(FileRegression_daily) and ow_daily != 1:\n",
    "#     print('Condition-1:', FileRegression_daily, 'exists')\n",
    "#     print('Condition-2: ow_daily != 1')\n",
    "#     sys.exit('Output files have been generated. Exit the program')\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# 1. basic information\n",
    "\n",
    "print('Read study area basic information')\n",
    "# station location and attribute information\n",
    "# stninfo: [ stations, 1/lat/lon/elev/slope_ns/slope_we ]\n",
    "stnID, stninfo = au.readstnlist(FileStnInfo)\n",
    "nstn = len(stnID)\n",
    "\n",
    "# time information\n",
    "if date_cal_start < date_stn_start:\n",
    "    sys.exit('The calculation period is earlier than the station period')\n",
    "if date_cal_end > date_stn_end:\n",
    "    sys.exit('The calculation period is later than the station period')\n",
    "\n",
    "date_cal_start2 = dt.datetime.strptime(str(date_cal_start), '%Y%m%d')\n",
    "date_cal_end2 = dt.datetime.strptime(str(date_cal_end), '%Y%m%d')\n",
    "ntimes = (date_cal_end2 - date_cal_start2).days + 1  # time steps to be processed\n",
    "\n",
    "date_stn_start2 = dt.datetime.strptime(str(date_stn_start), '%Y%m%d')\n",
    "loc_start = (date_cal_start2 - date_stn_start2).days  # start location in the netcdf file\n",
    "loc_end = loc_start + ntimes\n",
    "\n",
    "# seconds since 1970-1-1 0:0:0\n",
    "daydiff = (date_cal_start2 - dt.datetime(1970, 1, 1)).days\n",
    "seconds = (np.arange(ntimes) + daydiff) * 86400\n",
    "\n",
    "# datelist: yyyymmdd\n",
    "yyyymmdd = np.zeros(ntimes, dtype=int)\n",
    "for d in range(ntimes):\n",
    "    dated = date_cal_start2 + dt.timedelta(days=d)\n",
    "    yyyymmdd[d] = int(dated.strftime(\"%Y%m%d\"))\n",
    "yyyymm = np.floor(yyyymmdd / 100).astype(int)\n",
    "mm = np.floor(np.mod(yyyymmdd, 10000) / 100).astype(int)\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# 2. read study area basic information\n",
    "print('Read study area basic information')\n",
    "ncfid = nc.Dataset(FileGridInfo)\n",
    "gridlat = ncfid.variables['latitude'][:].data\n",
    "gridlon = ncfid.variables['longitude'][:].data\n",
    "gridele = ncfid.variables['elev'][:].data\n",
    "gridgns = ncfid.variables['gradient_n_s'][:].data\n",
    "gridgwe = ncfid.variables['gradient_w_e'][:].data\n",
    "mask = ncfid.variables['mask'][:].data  # 1: grids to be considered; the other values: invalid grids\n",
    "ncfid.close()\n",
    "\n",
    "nrows, ncols = np.shape(gridlat)\n",
    "gridinfo = np.zeros([nrows, ncols, 6])\n",
    "gridinfo[:, :, 0] = 1\n",
    "gridinfo[:, :, 1] = gridlat\n",
    "gridinfo[:, :, 2] = gridlon\n",
    "gridinfo[:, :, 3] = gridele\n",
    "gridinfo[:, :, 4] = gridgns\n",
    "gridinfo[:, :, 5] = gridgwe\n",
    "del gridlat, gridlon, gridele, gridgns, gridgwe\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# 3. read data (prcp, tmin, tmax) from station files\n",
    "print('Read station precipitation and temperature data')\n",
    "if os.path.isfile(FileStnData) and ow_stn != 1:\n",
    "    print('FileStnData exists. loading ...')\n",
    "    with np.load(FileStnData) as datatemp:\n",
    "        prcp_stn_daily = datatemp['prcp_stn_daily']\n",
    "        tmean_stn_daily = datatemp['tmean_stn_daily']\n",
    "        trange_stn_daily = datatemp['trange_stn_daily']\n",
    "        prcp_stn_climo = datatemp['prcp_stn_climo']\n",
    "        tmean_stn_climo = datatemp['tmean_stn_climo']\n",
    "        trange_stn_climo = datatemp['trange_stn_climo']\n",
    "        prcp_stn_anom = datatemp['prcp_stn_anom']\n",
    "        tmean_stn_anom = datatemp['tmean_stn_anom']\n",
    "        trange_stn_anom = datatemp['trange_stn_anom']\n",
    "\n",
    "else:\n",
    "    prcp_stn_daily, tmean_stn_daily, trange_stn_daily, \\\n",
    "    prcp_stn_climo, tmean_stn_climo, trange_stn_climo, \\\n",
    "    prcp_stn_anom, tmean_stn_anom, trange_stn_anom \\\n",
    "        = au.read_station(PathStn, stnID, loc_start, loc_end, cai_mode, yyyymm)\n",
    "    np.savez_compressed(FileStnData,\n",
    "                        prcp_stn_daily=prcp_stn_daily, tmean_stn_daily=tmean_stn_daily, trange_stn_daily=trange_stn_daily,\n",
    "                        prcp_stn_climo=prcp_stn_climo, tmean_stn_climo=tmean_stn_climo, trange_stn_climo=trange_stn_climo,\n",
    "                        prcp_stn_anom=prcp_stn_anom, tmean_stn_anom=tmean_stn_anom, trange_stn_anom=trange_stn_anom)\n",
    "\n",
    "if cai_mode == 0:\n",
    "    del prcp_stn_climo, tmean_stn_climo, trange_stn_climo, prcp_stn_anom, tmean_stn_anom, trange_stn_anom\n",
    "elif daily_flag != 1:\n",
    "    del prcp_stn_daily, tmean_stn_daily, trange_stn_daily\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# 4. calculate auto_corr and t_p_corr\n",
    "print('Calculate correlation (auto_cc and t_p_cc)')\n",
    "if cai_mode == 0 or daily_flag == 1:\n",
    "    mean_autocorr_daily, mean_tp_corr_daily = au.cc_calculate(windows, lag, prcp_stn_daily, tmean_stn_daily,\n",
    "                                                              trange_stn_daily)\n",
    "    print('Tmean lag-1 daily autocorrelation: ', mean_autocorr_daily)\n",
    "    print('Trange-prcp daily correlation: ', mean_tp_corr_daily)\n",
    "\n",
    "if cai_mode == 1:\n",
    "    mean_autocorr_climo, mean_tp_corr_climo = au.cc_calculate(1, lag, prcp_stn_climo, tmean_stn_climo, trange_stn_climo)\n",
    "    print('Tmean lag-1 climo autocorrelation: ', mean_autocorr_climo)\n",
    "    print('Trange-prcp climo correlation: ', mean_tp_corr_climo)\n",
    "\n",
    "    mean_autocorr_anom, mean_tp_corr_anom = au.cc_calculate(1, lag, prcp_stn_anom, tmean_stn_anom, trange_stn_anom)\n",
    "    print('Tmean lag-1 anom autocorrelation: ', mean_autocorr_anom)\n",
    "    print('Trange-prcp anom correlation: ', mean_tp_corr_anom)\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# 5. find neighboring stations and calculate distance-based weights\n",
    "if os.path.isfile(FileWeight) and ow_weight != 1:\n",
    "    print('FileWeight exists. loading ...')\n",
    "    with np.load(FileWeight) as datatemp:\n",
    "        near_grid_prcpLoc = datatemp['near_grid_prcpLoc']\n",
    "        near_grid_prcpWeight = datatemp['near_grid_prcpWeight']\n",
    "        near_grid_tempLoc = datatemp['near_grid_tempLoc']\n",
    "        near_grid_tempWeight = datatemp['near_grid_tempWeight']\n",
    "        near_stn_prcpLoc = datatemp['near_stn_prcpLoc']\n",
    "        near_stn_prcpWeight = datatemp['near_stn_prcpWeight']\n",
    "        near_stn_tempLoc = datatemp['near_stn_tempLoc']\n",
    "        near_stn_tempWeight = datatemp['near_stn_tempWeight']\n",
    "    del datatemp\n",
    "else:\n",
    "    near_grid_prcpLoc, near_grid_prcpDist, near_grid_prcpWeight, \\\n",
    "    near_grid_tempLoc, near_grid_tempDist, near_grid_tempWeight, \\\n",
    "    near_stn_prcpLoc, near_stn_prcpDist, near_stn_prcpWeight, \\\n",
    "    near_stn_tempLoc, near_stn_tempDist, near_stn_tempWeight \\\n",
    "        = au.station_weight(prcp_stn_daily, tmean_stn_daily, stninfo, gridinfo, mask,\n",
    "                            search_radius, nearstn_min, nearstn_max, max_dist)\n",
    "\n",
    "    # save data\n",
    "    np.savez_compressed(FileWeight, near_grid_prcpLoc=near_grid_prcpLoc, near_grid_prcpDist=near_grid_prcpDist,\n",
    "                        near_grid_prcpWeight=near_grid_prcpWeight, near_grid_tempLoc=near_grid_tempLoc,\n",
    "                        near_grid_tempDist=near_grid_tempDist, near_grid_tempWeight=near_grid_tempWeight,\n",
    "                        near_stn_prcpLoc=near_stn_prcpLoc, near_stn_prcpDist=near_stn_prcpDist,\n",
    "                        near_stn_prcpWeight=near_stn_prcpWeight, near_stn_tempLoc=near_stn_tempLoc,\n",
    "                        near_stn_tempDist=near_stn_tempDist, near_stn_tempWeight=near_stn_tempWeight)\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# 6. start spatial regression\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# 6.1 estimate regression error at station points\n",
    "# 6.1.1 daily mode\n",
    "if cai_mode == 0 or daily_flag == 1:\n",
    "    if os.path.isfile(FileRegError_daily) and ow_daily != 1:\n",
    "        print('FileRegError_daily exists. loading ...')\n",
    "        with np.load(FileRegError_daily) as datatemp:\n",
    "            pcp_err_stn_daily = datatemp['pcp_err_stn']\n",
    "            tmean_err_stn_daily = datatemp['tmean_err_stn']\n",
    "            trange_err_stn_daily = datatemp['trange_err_stn']\n",
    "        del datatemp\n",
    "    else:\n",
    "        print('Estimate daily regression error at station points')\n",
    "        pcp_err_stn_daily, tmean_err_stn_daily, trange_err_stn_daily = \\\n",
    "            reg.station_error(prcp_stn_daily, tmean_stn_daily, trange_stn_daily, stninfo, near_stn_prcpLoc,\n",
    "                              near_stn_prcpWeight, near_stn_tempLoc, near_stn_tempWeight, trans_exp_daily,\n",
    "                              trans_mode, nearstn_min)\n",
    "        np.savez_compressed(FileRegError_daily, pcp_err_stn=pcp_err_stn_daily, tmean_err_stn=tmean_err_stn_daily,\n",
    "                            trange_err_stn=trange_err_stn_daily, stninfo=stninfo)\n",
    "\n",
    "# 8.1 evaluate regression for each station\n",
    "kge_stn = [0] * 3\n",
    "metric_stn = [0]*3\n",
    "for i in range(3):\n",
    "    kge_stn[i] = np.zeros([nstn, 4])\n",
    "    metric_stn[i] = np.zeros([nstn, 4])\n",
    "\n",
    "for i in range(nstn):\n",
    "    obs = prcp_stn_daily[i, :].copy()\n",
    "    obst = au.transform(obs, trans_exp_daily, trans_mode)\n",
    "    est = au.retransform(obst + pcp_err_stn_daily[i, :], trans_exp_daily, trans_mode)\n",
    "    kge_stn[0][i, :] = au.kge2012(obs, est)\n",
    "    metric_stn[0][i, :] = au.metric(obs, est)\n",
    "\n",
    "    obs = tmean_stn_daily[i, :]\n",
    "    est = obs + tmean_err_stn_daily[i, :]\n",
    "    kge_stn[1][i, :] = au.kge2012(obs, est)\n",
    "    metric_stn[1][i, :] = au.metric(obs, est)\n",
    "\n",
    "    obs = trange_stn_daily[i, :]\n",
    "    est = obs + trange_err_stn_daily[i, :]\n",
    "    kge_stn[2][i, :] = au.kge2012(obs, est)\n",
    "    metric_stn[2][i, :] = au.metric(obs, est)\n",
    "\n",
    "np.nanmedian(kge_stn[0],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.savemat('pcp.mat',{'pcpobs':prcp_stn_daily,'pcpest':prcp_stn_daily_est})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
