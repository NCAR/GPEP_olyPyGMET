{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year--var: 1979 prcp\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import auxiliary as au\n",
    "import regression as reg\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import io\n",
    "from scipy.interpolate import interp2d\n",
    "import os\n",
    "import sys\n",
    "from scipy.interpolate import griddata\n",
    "import h5py\n",
    "\n",
    "\n",
    "def demread(file, lattar, lontar):\n",
    "    datatemp = io.loadmat(file)\n",
    "    demori = datatemp['DEM']\n",
    "    demori[np.isnan(demori)] = 0\n",
    "    info = datatemp['Info'][0][0]\n",
    "    latori = np.arange(info['yll'] + info['Ysize'] * info['nrows'] - info['Ysize'] / 2, info['yll'], -info['Ysize'])\n",
    "    lonori = np.arange(info['xll'] + info['Xsize'] / 2, info['xll'] + info['Xsize'] * info['ncols'], info['Xsize'])\n",
    "    f = interp2d(lonori, latori, demori, kind='linear')\n",
    "    demtar = f(lontar.flatten(), lattar.flatten())\n",
    "    demtar = np.flipud(demtar)\n",
    "    return demtar\n",
    "\n",
    "\n",
    "def ncread(file, var):\n",
    "    # read a variable from netcdf\n",
    "    ncfid = nc.Dataset(file)\n",
    "    data = ncfid[var][:].data\n",
    "    ncfid.close()\n",
    "    return data\n",
    "\n",
    "\n",
    "def neargrid(rowtar, coltar, rowori, colori, hwsize):\n",
    "    # inputs are 1D matrices\n",
    "    # tar is target area\n",
    "    # ori is original area\n",
    "    # hwsize is half window size (e.g., 4 means the space window width/length is 2*4+1)\n",
    "    # find a space window centering the target grid in the original area and calculate the weights\n",
    "    nrows = len(rowtar)\n",
    "    ncols = len(coltar)\n",
    "    rowse = np.zeros([nrows, ncols, 2]).astype(int)  # se: start/end\n",
    "    colse = np.zeros([nrows, ncols, 2]).astype(int)  # se: start/end\n",
    "    weight = np.nan * np.zeros([nrows, ncols, (hwsize * 2 + 1) ** 2])  # from left to right/from top to bottom weight\n",
    "\n",
    "    for rr in range(nrows):\n",
    "        rowloc = np.argmin(np.abs(rowori - rowtar[rr]))\n",
    "        rowse[rr, :, 0] = rowloc - hwsize\n",
    "        rowse[rr, :, 1] = rowloc + hwsize\n",
    "\n",
    "    for cc in range(ncols):\n",
    "        colloc = np.argmin(np.abs(colori - coltar[cc]))\n",
    "        colse[:, cc, 0] = colloc - hwsize\n",
    "        colse[:, cc, 1] = colloc + hwsize\n",
    "\n",
    "    rowse[rowse < 0] = 0\n",
    "    rowse[rowse > nrows] = nrows\n",
    "    colse[colse < 0] = 0\n",
    "    colse[colse > ncols] = nrows\n",
    "\n",
    "    maxdist = (hwsize + 0.5) * np.sqrt(2) + 0.5\n",
    "    for rr in range(nrows):\n",
    "        rowloc = np.argmin(np.abs(rowori - rowtar[rr]))\n",
    "        for cc in range(ncols):\n",
    "            colloc = np.argmin(np.abs(colori - coltar[cc]))\n",
    "\n",
    "            rowse_rc = rowse[rr, cc, :]\n",
    "            colse_rc = colse[rr, cc, :]\n",
    "            flag = 0\n",
    "            for i in range(rowse_rc[0], rowse_rc[1] + 1):\n",
    "                for j in range(colse_rc[0], colse_rc[1] + 1):\n",
    "                    dist = ((rowloc - i) ** 2 + (colloc - j) ** 2) ** 0.5\n",
    "                    weight[rr, cc, flag] = au.distanceweight(dist, maxdist, 3)\n",
    "                    flag = flag + 1\n",
    "\n",
    "            weight[rr, cc, :] = weight[rr, cc, :] / np.nansum(weight[rr, cc, :])\n",
    "\n",
    "    return rowse, colse, weight\n",
    "\n",
    "\n",
    "def readownscale(dataori, latori, lonori, demori, lattar, lontar, demtar, rowse, colse, weight, mask):\n",
    "    nrows = len(lattar)\n",
    "    ncols = len(lontar)\n",
    "    ntimes = np.shape(dataori)[2]\n",
    "    lonori, latori = np.meshgrid(lonori, latori)\n",
    "    datatar = np.nan * np.zeros([nrows, ncols, ntimes])\n",
    "\n",
    "    for rr in range(nrows):\n",
    "        for cc in range(ncols):\n",
    "            if mask[rr, cc] == 1:\n",
    "                rloc = rowse[rr, cc, :]\n",
    "                cloc = colse[rr, cc, :]\n",
    "                latnear = latori[rloc[0]:rloc[1] + 1, cloc[0]:cloc[1] + 1]\n",
    "                lonnear = lonori[rloc[0]:rloc[1] + 1, cloc[0]:cloc[1] + 1]\n",
    "                demnear = demori[rloc[0]:rloc[1] + 1, cloc[0]:cloc[1] + 1]\n",
    "                nnum = np.size(latnear)\n",
    "                latnear = np.reshape(latnear, nnum)\n",
    "                lonnear = np.reshape(lonnear, nnum)\n",
    "                demnear = np.reshape(demnear, nnum)\n",
    "                weightnear = np.zeros([nnum, nnum])\n",
    "                for i in range(nnum):\n",
    "                    weightnear[i, i] = weight[rr, cc, i]\n",
    "\n",
    "                nearinfo = np.zeros([nnum, 4])\n",
    "                nearinfo[:, 0] = 1\n",
    "                nearinfo[:, 1] = latnear\n",
    "                nearinfo[:, 2] = lonnear\n",
    "                nearinfo[:, 3] = demnear\n",
    "\n",
    "                tarinfo = np.zeros(4)\n",
    "                tarinfo[0] = 1\n",
    "                tarinfo[1] = lattar[rr]\n",
    "                tarinfo[2] = lontar[cc]\n",
    "                tarinfo[3] = demtar[rr, cc]\n",
    "\n",
    "                tx_red = np.transpose(nearinfo)\n",
    "                twx_red = np.matmul(tx_red, weightnear)\n",
    "\n",
    "                for tt in range(1):\n",
    "                    datanear = dataori[rloc[0]:rloc[1] + 1, cloc[0]:cloc[1] + 1, tt]\n",
    "                    datanear = np.reshape(datanear, nnum)\n",
    "\n",
    "                    # upper and lower boundary for the downscaled data\n",
    "                    # this is a conservative limitation\n",
    "                    lowbound = np.min(datanear)\n",
    "                    upbound = np.max(datanear)\n",
    "\n",
    "                    b = reg.least_squares(nearinfo, datanear, twx_red)\n",
    "                    datatemp = np.dot(tarinfo, b)\n",
    "                    if np.all(b == 0) or datatemp>upbound or datatemp<lowbound:\n",
    "                        # use nearest neighbor interpolation\n",
    "                        weightnear = weight[rr, cc, 0:nnum]\n",
    "                        mloc = np.argmax(weightnear)\n",
    "                        datatar[rr, cc, tt] = datanear[mloc]\n",
    "                    else:\n",
    "                        datatar[rr, cc, tt] = datatemp\n",
    "\n",
    "    return datatar\n",
    "\n",
    "# input parameters\n",
    "# a = int(sys.argv[1])\n",
    "# b = int(sys.argv[2])\n",
    "# year = [a, b]\n",
    "# print('year',year)\n",
    "\n",
    "# basic information\n",
    "# mac\n",
    "filedem = './DEM/NA_DEM_010deg_trim.mat'\n",
    "# plato\n",
    "# filedem = '/datastore/GLOBALWATER/CommonData/EMDNA/DEM/NA_DEM_010deg_trim.mat'\n",
    "\n",
    "year = [1979, 1979]\n",
    "vars = ['prcp', 'tmin', 'tmax']\n",
    "lontar = np.arange(-180 + 0.05, -50, 0.1)\n",
    "lattar = np.arange(85 - 0.05, 5, -0.1)\n",
    "hwsize = 2\n",
    "\n",
    "datatemp = io.loadmat(filedem)\n",
    "demtar = datatemp['DEM']  # this is consistent with lontar lattar\n",
    "mask = demtar.copy()\n",
    "mask[~np.isnan(mask)] = 1\n",
    "\n",
    "# ERA-5\n",
    "# mac\n",
    "filedem_era = './DEM/ERA5_DEM2.mat'\n",
    "inpath = '/Users/localuser/Research/Test'\n",
    "outpath = '/Users/localuser/Research'\n",
    "# plato\n",
    "# filedem_era = '/datastore/GLOBALWATER/CommonData/EMDNA/DEM/ERA5_DEM2.mat'\n",
    "# inpath = '/datastore/GLOBALWATER/CommonData/EMDNA/ERA5_day_raw'\n",
    "# outpath = '/home/gut428/ERA5_day_ds'\n",
    "filenear = outpath + '/weight_dem.npz'\n",
    "\n",
    "for y in range(year[0], year[1] + 1):\n",
    "    for v in range(1):\n",
    "        print('year--var:', y, vars[v])\n",
    "        infile = inpath + '/ERA5_' + vars[v] + '_' + str(y) + '.mat'\n",
    "        outfile = outpath + '/ERA5_' + vars[v] + '_' + str(y) + '.npz'\n",
    "        if os.path.isfile(outfile):\n",
    "            continue\n",
    "\n",
    "        # load original daily reanalysis data\n",
    "        datatemp = {}\n",
    "        f = h5py.File(infile,'r')\n",
    "        for k, v in f.items():\n",
    "            datatemp[k] = np.array(v)\n",
    "        latori = datatemp['latitude'][0]\n",
    "        lonori = datatemp['longitude'][0]\n",
    "        dataori = datatemp['data']\n",
    "        dataori = np.transpose(dataori, [2, 1, 0])\n",
    "        del datatemp\n",
    "        f.close()\n",
    "\n",
    "        # read location information\n",
    "        if not os.path.isfile(filenear):\n",
    "            rowse, colse, weight = neargrid(lattar, lontar, latori, lonori, hwsize)\n",
    "            # extract ori dem\n",
    "            demori = demread(filedem_era, latori, lonori)\n",
    "            io.savemat(filenear, {'rowse': rowse, 'colse': colse, 'weight': weight, 'demori': demori})\n",
    "        else:\n",
    "            datatemp = io.loadmat(filenear)\n",
    "            rowse = datatemp['rowse']\n",
    "            colse = datatemp['colse']\n",
    "            weight = datatemp['weight']\n",
    "            demori = datatemp['demori']\n",
    "            del datatemp\n",
    "\n",
    "        # downscale the reanalysis to 0.1 degree\n",
    "        datatar = readownscale(dataori, latori, lonori, demori, lattar, lontar, demtar, rowse, colse, weight, mask)\n",
    "        datatar = np.float32(datatar)\n",
    "#         np.savez_compressed(outfile, data=datatar, latitude=lattar, longitude=lontar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "716376"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(demtar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
