{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start basic processing\n",
      "load near station information for points\n",
      "load near station information for grids\n",
      "load downscaled reanalysis data at station points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:741: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load independent merged/corrected data at station points\n",
      "load merge choice file\n",
      "Correction and Merge: year 2000\n",
      "Correction and Merge: month 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: Mean of empty slice\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:95: RuntimeWarning: Mean of empty slice\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:98: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:98: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:106: RuntimeWarning: invalid value encountered in greater\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:107: RuntimeWarning: invalid value encountered in less\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:284: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correction and Merge: month 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-5c23dbf0745e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0mcorr_datam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorr_errorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_datam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_errorm\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m             correct_merge(stndata[:, indym], readata_raw[:,:,:,indm], readata_stn[:, :, indym], reacorr_stn[:, :, indym],\n\u001b[0m\u001b[1;32m    876\u001b[0m                           \u001b[0mreamerge_stn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindym\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreamerge_weight_stn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneargrid_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneargrid_dist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m                           merge_choice[m, :, :], mask, hwsize, corrmode, anombound, var, weightmode)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import auxiliary as au\n",
    "import regression as reg\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import io\n",
    "from scipy.interpolate import interp2d\n",
    "import os\n",
    "import sys\n",
    "from scipy.interpolate import griddata\n",
    "import h5py\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "from bma_merge import bma\n",
    "\n",
    "\n",
    "def divide_train_test(data, dividenum, randseed=-1):\n",
    "    if randseed == -1:\n",
    "        random.seed(time.time())\n",
    "    num = len(data)\n",
    "    subnum = int(num / dividenum)\n",
    "    data_train = np.zeros([dividenum, num - subnum], dtype=int)\n",
    "    data_test = np.zeros([dividenum, subnum], dtype=int)\n",
    "    randindex = random.sample(range(num), num)\n",
    "    for i in range(dividenum):\n",
    "        data_test[i, :] = np.sort(data[randindex[i * subnum:(i + 1) * subnum]])\n",
    "        data_train[i, :] = np.setdiff1d(data, data_test[i])\n",
    "    return data_train, data_test\n",
    "\n",
    "\n",
    "def double_cvindex(gmet_stndatafile, dividenum, rndseed=123):\n",
    "    # index for double cross-validation\n",
    "    datatemp = np.load(gmet_stndatafile)\n",
    "    prcp_stn0 = datatemp['prcp_stn'][:, 0]\n",
    "    tmean_stn0 = datatemp['tmean_stn'][:, 0]\n",
    "    prcp_stnindex = np.argwhere(~np.isnan(prcp_stn0))\n",
    "    prcp_stnindex = prcp_stnindex.flatten()\n",
    "    tmean_stnindex = np.argwhere(~np.isnan(tmean_stn0))\n",
    "    tmean_stnindex = tmean_stnindex.flatten()\n",
    "\n",
    "    subnum1 = int(len(prcp_stnindex) / dividenum)\n",
    "    subnum2 = int((len(prcp_stnindex) - subnum1) / dividenum)\n",
    "    # prcp_testindex1 = np.zeros([dividenum,subnum1])\n",
    "    # prcp_trainindex1 = np.zeros([dividenum,len(prcp_stnindex) - subnum1])\n",
    "    prcp_trainindex1, prcp_testindex1 = divide_train_test(prcp_stnindex, dividenum, randseed=rndseed)\n",
    "    prcp_testindex2 = np.zeros([dividenum, dividenum, subnum2], dtype=int)\n",
    "    prcp_trainindex2 = np.zeros([dividenum, dividenum, len(prcp_stnindex) - subnum1 - subnum2], dtype=int)\n",
    "    for i in range(dividenum):\n",
    "        traini, testi = divide_train_test(prcp_trainindex1[i, :], dividenum, randseed=rndseed)\n",
    "        prcp_trainindex2[i, :, :] = traini\n",
    "        prcp_testindex2[i, :, :] = testi\n",
    "\n",
    "    subnum1 = int(len(tmean_stnindex) / dividenum)\n",
    "    subnum2 = int((len(tmean_stnindex) - subnum1) / dividenum)\n",
    "    # tmean_testindex1 = np.zeros([dividenum,subnum1])\n",
    "    # tmean_trainindex1 = np.zeros([dividenum,len(tmean_stnindex) - subnum1])\n",
    "    tmean_trainindex1, tmean_testindex1 = divide_train_test(tmean_stnindex, dividenum, randseed=rndseed)\n",
    "    tmean_testindex2 = np.zeros([dividenum, dividenum, subnum2], dtype=int)\n",
    "    tmean_trainindex2 = np.zeros([dividenum, dividenum, len(tmean_stnindex) - subnum1 - subnum2], dtype=int)\n",
    "    for i in range(dividenum):\n",
    "        traini, testi = divide_train_test(tmean_trainindex1[i, :], dividenum, randseed=rndseed)\n",
    "        tmean_trainindex2[i, :, :] = traini\n",
    "        tmean_testindex2[i, :, :] = testi\n",
    "    return prcp_trainindex1, prcp_testindex1, prcp_trainindex2, prcp_testindex2, \\\n",
    "           tmean_trainindex1, tmean_testindex1, tmean_trainindex2, tmean_testindex2\n",
    "\n",
    "\n",
    "def calculate_anomaly(datatar, dataref, hwsize, amode, upbound=5, lowbound=0.2):\n",
    "    # datatar, dataref: 2D [nstn, ntime]\n",
    "    # amode: anomaly mode ('ratio' or 'diff')\n",
    "    # hwsize: define time window (2*hwsize+1) used to calculate ratio (as ratio for a specific day is too variable)\n",
    "    # upbound/lowbound: upper and lower limitation of ratio/difference\n",
    "    if np.ndim(datatar) == 1:  # only one time step\n",
    "        datatar = datatar[:, np.newaxis]\n",
    "        dataref = dataref[:, np.newaxis]\n",
    "\n",
    "    nstn, ntime = np.shape(datatar)\n",
    "    if ntime < hwsize * 2 + 1:\n",
    "        print('The window size is larger than time steps when calculating ratio between tar and ref datasets')\n",
    "        print('Please set a smaller hwsize')\n",
    "        sys.exit()\n",
    "\n",
    "    anom = np.ones([nstn, ntime])\n",
    "\n",
    "    for i in range(ntime):\n",
    "        if i < hwsize:\n",
    "            windex = np.arange(hwsize * 2 + 1)\n",
    "        elif i >= ntime - hwsize:\n",
    "            windex = np.arange(ntime - hwsize * 2 - 1, ntime)\n",
    "        else:\n",
    "            windex = np.arange(i - hwsize, i + hwsize + 1)\n",
    "        dtari = np.nanmean(datatar[:, windex], axis=1)\n",
    "        drefi = np.nanmean(dataref[:, windex], axis=1)\n",
    "\n",
    "        if amode == 'ratio':\n",
    "            temp = drefi / dtari\n",
    "            temp[(dtari == 0) & (drefi == 0)] = 1\n",
    "            anom[:, i] = temp\n",
    "        elif amode == 'diff':\n",
    "            anom[:, i] = drefi - dtari\n",
    "        else:\n",
    "            sys.exit('Unknow amode. Please use either ratio or diff')\n",
    "\n",
    "    anom[anom > upbound] = upbound\n",
    "    anom[anom < lowbound] = lowbound\n",
    "    return anom\n",
    "\n",
    "\n",
    "def extrapolation(datain, nearstn_loc, nearstn_dist):\n",
    "    # datain: one or multiple time steps\n",
    "    wexp = 3\n",
    "    if np.ndim(datain) == 1:  # add time axis\n",
    "        datain = datain[:, np.newaxis]\n",
    "\n",
    "    if np.ndim(nearstn_loc) == 2:  # extrapolate to station points\n",
    "        num = np.shape(nearstn_loc)[0]\n",
    "        ntimes = np.shape(datain)[1]\n",
    "        dataout = np.nan * np.zeros([num, ntimes], dtype=np.float32)\n",
    "        for i in range(num):\n",
    "            if not nearstn_loc[i, 0]>=0:\n",
    "                continue\n",
    "            nearloci = nearstn_loc[i, :]\n",
    "            indloci = nearloci > -1\n",
    "            dataini = datain[nearloci[indloci], :]\n",
    "            disti = nearstn_dist[i, indloci]\n",
    "            weighti = au.distanceweight(disti, np.max(disti) + 1, wexp)\n",
    "            weighti[np.isnan(dataini[:,0])] = np.nan\n",
    "            weighti = weighti / np.nansum(weighti)\n",
    "            weighti2 = np.tile(weighti,[ntimes,1]).T\n",
    "            dataout[i, :] = np.nansum(dataini * weighti2, axis=0)\n",
    "    elif np.ndim(nearstn_loc) == 3:  # extrapolate to gridds\n",
    "        nrows, ncols, nearnum = np.shape(nearstn_loc)\n",
    "        nstn, ntimes = np.shape(datain)\n",
    "        dataout = np.nan * np.zeros([nrows, ncols, ntimes], dtype=np.float32)\n",
    "        for r in range(nrows):\n",
    "            for c in range(ncols):\n",
    "                if not nearstn_loc[r, c, 0]>=0:\n",
    "                    continue\n",
    "                nearloci = nearstn_loc[r, c, :]\n",
    "                indloci = nearloci > -1\n",
    "                dataini = datain[nearloci[indloci], :]\n",
    "                disti = nearstn_dist[r, c, indloci]\n",
    "                weighti = au.distanceweight(disti, np.max(disti) + 1, wexp)\n",
    "                weighti[np.isnan(dataini[:,0])]=np.nan\n",
    "                weighti = weighti / np.nansum(weighti)\n",
    "                weighti2 = np.tile(weighti, [ntimes, 1]).T\n",
    "                dataout[r, c, :] = np.nansum(dataini * weighti2, axis=0)\n",
    "    else:\n",
    "        print('The dimensions of tarlat or tarlon are larger than 2')\n",
    "        sys.exit()\n",
    "    if ntimes == 1:\n",
    "        dataout = np.squeeze(dataout)\n",
    "    return dataout\n",
    "\n",
    "\n",
    "def findnearstn(stnlat, stnlon, tarlat, tarlon, nearnum, noself):\n",
    "    # only use lat/lon to find near stations without considering distance in km\n",
    "    # stnlat/stnlon: 1D\n",
    "    # tarlat/tarlon: 1D or 2D\n",
    "    # noself: 1--stnlat and tarlat have overlapped stations, which should be excluded from stnlat\n",
    "\n",
    "    stnll = np.zeros([len(stnlat), 2])\n",
    "    stnll[:, 0] = stnlat\n",
    "    stnll[:, 1] = stnlon\n",
    "\n",
    "    if len(np.shape(tarlat)) == 1:\n",
    "        num = len(tarlat)\n",
    "        nearstn_loc = -1 * np.ones([num, nearnum], dtype=int)\n",
    "        nearstn_dist = -1 * np.ones([num, nearnum], dtype=float)\n",
    "        for i in range(num):\n",
    "            if np.isnan(tarlat[i]) or np.isnan(tarlon[i]):\n",
    "                continue\n",
    "            tari = np.array([tarlat[i], tarlon[i]])\n",
    "            dist = au.distance(tari, stnll)\n",
    "            dist[np.isnan(dist)] = 1000000000\n",
    "            if noself == 1:\n",
    "                dist[dist == 0] = np.inf  # may not be perfect, but work for SCDNA\n",
    "            indi = np.argsort(dist)\n",
    "            nearstn_loc[i, :] = indi[0:nearnum]\n",
    "            nearstn_dist[i, :] = dist[nearstn_loc[i, :]]\n",
    "    elif len(np.shape(tarlat)) == 2:\n",
    "        nrows, ncols = np.shape(tarlat)\n",
    "        nearstn_loc = -1 * np.ones([nrows, ncols, nearnum], dtype=int)\n",
    "        nearstn_dist = -1 * np.ones([nrows, ncols, nearnum], dtype=float)\n",
    "        for r in range(nrows):\n",
    "            for c in range(ncols):\n",
    "                if np.isnan(tarlat[r, c]) or np.isnan(tarlon[r, c]):\n",
    "                    continue\n",
    "                tari = np.array([tarlat[r, c], tarlon[r, c]])\n",
    "                dist = au.distance(tari, stnll)\n",
    "                dist[np.isnan(dist)] = 1000000000\n",
    "                indi = np.argsort(dist)\n",
    "                nearstn_loc[r, c, :] = indi[0:nearnum]\n",
    "                nearstn_dist[r, c, :] = dist[nearstn_loc[r, c, :]]\n",
    "    else:\n",
    "        print('The dimensions of tarlat or tarlon are larger than 2')\n",
    "        sys.exit()\n",
    "\n",
    "    return nearstn_loc, nearstn_dist\n",
    "\n",
    "\n",
    "def error_correction(dataori, anomaly, mode='ratio'):\n",
    "    # default: time is the last dimension\n",
    "    if mode == 'ratio':\n",
    "        datacorr = dataori * anomaly\n",
    "    elif mode == 'diff':\n",
    "        datacorr = dataori + anomaly\n",
    "    else:\n",
    "        sys.exit('Wrong error correction mode')\n",
    "    return datacorr\n",
    "\n",
    "\n",
    "def calweight(obsall, preall, mode='RMSE', preprocess=True):\n",
    "    nstn, ntime = np.shape(obsall)\n",
    "    met = np.nan * np.zeros(nstn)\n",
    "    for i in range(nstn):\n",
    "        obs = obsall[i, :]\n",
    "        pre = preall[i, :]\n",
    "        if preprocess:\n",
    "            # delete the nan values\n",
    "            ind_nan = np.isnan(obs) | np.isnan(pre)\n",
    "            obs = obs[~ind_nan]\n",
    "            pre = pre[~ind_nan]\n",
    "\n",
    "        if len(obs) < 3:\n",
    "            continue\n",
    "\n",
    "        if mode == 'RMSE':\n",
    "            met[i] = np.sqrt(np.sum(np.square(obs - pre)) / len(obs))  # RMSE\n",
    "        elif mode == 'CC':\n",
    "            temp = np.corrcoef(obs, pre)\n",
    "            met[i] = temp[0][1]  # CC\n",
    "        else:\n",
    "            sys.exit('Unknown inputs for calmetric')\n",
    "\n",
    "    if mode == 'RMSE':\n",
    "        met[met==0] = 0.01\n",
    "        weight = 1 / (met ** 2)\n",
    "    elif mode == 'CC':\n",
    "        met[met < 0] = 0\n",
    "        weight = met ** 2\n",
    "    else:\n",
    "        sys.exit('Unknown inputs for calmetric')\n",
    "\n",
    "    return weight\n",
    "\n",
    "\n",
    "def calmetric(dtar, dref, metname='RMSE'):\n",
    "    if np.ndim(dtar) == 1:\n",
    "        dtar = dtar[np.newaxis, :]\n",
    "        dref = dref[np.newaxis, :]\n",
    "    nstn, ntimes = np.shape(dtar)\n",
    "    metout = np.nan * np.zeros(nstn, dtype=np.float32)\n",
    "    if metname == 'RMSE':\n",
    "        for i in range(nstn):\n",
    "            metout[i] = np.sqrt(np.nansum(np.square(dtar[i, :] - dref[i, :])) / ntimes)  # RMSE\n",
    "    elif metname == 'CC':\n",
    "        for i in range(nstn):\n",
    "            temp = np.corrcoef(dtar[i, :], dref[i, :])\n",
    "            metout[i] = temp[0, 1]\n",
    "    else:\n",
    "        sys.exit('Unkown metric name')\n",
    "    return metout\n",
    "\n",
    "\n",
    "def ismember(a, b):\n",
    "    # tf = np.in1d(a,b) # for newer versions of numpy\n",
    "    tf = np.array([i in b for i in a])\n",
    "    u = np.unique(a[tf])\n",
    "    index = np.array([(np.where(b == i))[0][-1] if t else 0 for i, t in zip(a, tf)])\n",
    "    return tf, index\n",
    "\n",
    "\n",
    "def weightmerge(data, weight):\n",
    "    if np.ndim(data) == 2:\n",
    "        weight2 = weight.copy()\n",
    "        weight2[np.isnan(data)] = np.nan\n",
    "        dataout = np.nansum(data * weight2, axis=1) / np.nansum(weight2, axis=1)\n",
    "    elif np.ndim(data) == 3:\n",
    "        weight2 = weight.copy()\n",
    "        weight2[np.isnan(data)] = np.nan\n",
    "        dataout = np.nansum(data * weight2, axis=2) / np.nansum(weight2, axis=2)\n",
    "        dataout[np.isnan(data[:,:,0])]=np.nan\n",
    "    return dataout\n",
    "\n",
    "\n",
    "def m_DateList(year_start, year_end, mode):\n",
    "    # generate a date list (yyyymmdd) between start year and end year\n",
    "    # mode: 'ByDay', 'ByMonth', 'ByYear': time scales of input files\n",
    "    date_start = datetime.date(year_start, 1, 1)\n",
    "    date_end = datetime.date(year_end, 12, 31)\n",
    "    daynum = (date_end - date_start).days + 1\n",
    "\n",
    "    # generate date in format: yyyymmdd\n",
    "    date_ymd = np.zeros(daynum, dtype=int)\n",
    "    dated = date_start\n",
    "    for d in range(daynum):\n",
    "        if d > 0:\n",
    "            dated = dated + datetime.timedelta(days=1)\n",
    "        date_ymd[d] = int(dated.strftime(\"%Y%m%d\"))\n",
    "    date_number = {'yyyymmdd': date_ymd,\n",
    "                   'yyyymm': np.floor(date_ymd / 100).astype(int),\n",
    "                   'yyyy': np.floor(date_ymd / 10000).astype(int),\n",
    "                   'mm': np.floor(np.mod(date_ymd, 10000) / 100).astype(int),\n",
    "                   'dd': np.mod(date_ymd, 100).astype(int)}\n",
    "\n",
    "    # generate file list\n",
    "    if mode == 'ByDay':\n",
    "        datemode = date_number['yyyymmdd']\n",
    "    else:\n",
    "        if mode == 'ByMonth':\n",
    "            datemode = date_number['yyyymm']\n",
    "        elif mode == 'ByYear':\n",
    "            datemode = date_number['yyyy']\n",
    "        datemode = np.unique(datemode)\n",
    "\n",
    "    date_list = [' '] * len(datemode)\n",
    "    for i in range(len(datemode)):\n",
    "        date_list[i] = str(datemode[i])\n",
    "\n",
    "    return date_list, date_number\n",
    "\n",
    "def box_cox_transform(data, exp=0.25):\n",
    "    return (data ** exp - 1) / exp\n",
    "\n",
    "def box_cox_recover(data, exp=0.25):\n",
    "    dataout = (data * exp + 1) ** (1/exp)\n",
    "    dataout[data < -1/exp] = 0\n",
    "    return dataout\n",
    "\n",
    "def merge_correction_stnerror(outpath, stnlle, stndata, readata_stn, taintestindex, nearstn_locl1, nearstn_distl1,\n",
    "         nearstn_locl2, nearstn_distl2, dividenum, var, hwsize, corrmode, anombound, weightmode):\n",
    "    # use 2-layer cross-validation to estimate the weight and independent data of merge/correction data\n",
    "    # layer-1: aim to obtain correction and merged data at station points through cross-validation\n",
    "    # layer-2: aim to obtain independent evaluation of correction data to support calculating merging weight in layer-1\n",
    "    reanum, nstn, ntimes = np.shape(readata_stn)\n",
    "\n",
    "    # initialization\n",
    "    reacorr_stn = np.nan * np.zeros([reanum, nstn, ntimes], dtype=np.float32)  # corrected reanalysis data\n",
    "    reamerge_weight_stn = np.nan * np.zeros([nstn, reanum])  # weight used to obtain reamerge_stn\n",
    "    reamerge_stn = np.nan * np.zeros([nstn, ntimes], dtype=np.float32)  # merged reanalysis at station points\n",
    "\n",
    "    for lay1 in range(dividenum):\n",
    "        print('Correction/Merging at station points. Layer-1:', lay1)\n",
    "        # extract train and test index for layer-1\n",
    "        if var == 'trange':\n",
    "            vari = 'tmean'  # trange and tmean have the same index\n",
    "        else:\n",
    "            vari = var\n",
    "        trainindex1 = taintestindex[vari + '_trainindex1'][lay1, :]\n",
    "        testindex1 = taintestindex[vari + '_testindex1'][lay1, :]\n",
    "        stndata_trainl1 = stndata[trainindex1, :]\n",
    "        stndata_testl1 = stndata[testindex1, :]\n",
    "        stnlle_trainl1 = stnlle[trainindex1, :]\n",
    "        stnlle_testl1 = stnlle[testindex1, :]\n",
    "\n",
    "        # filename: save inputs for each layer-1\n",
    "        file_reacorrl1 = outpath + '/' + var + '_layer_' + str(lay1 + 1) + '_' + weightmode + '.npz'\n",
    "        if os.path.isfile(file_reacorrl1):\n",
    "            datatemp = np.load(file_reacorrl1)\n",
    "            weight_trainl1 = datatemp['reaweight']\n",
    "            del datatemp\n",
    "        else:\n",
    "\n",
    "            # layer-2: start\n",
    "            reacorr_trainl1 = np.zeros([reanum, len(trainindex1), ntimes], dtype=np.float32)\n",
    "            weight_trainl1 = np.zeros([len(trainindex1), reanum], dtype=np.float32)\n",
    "\n",
    "            for lay2 in range(dividenum):\n",
    "                # print('Correction/Merging at station points. Layer-2:', lay2)\n",
    "                # extract train and test index for layer-2 (subsets of trainindex1)\n",
    "                trainindex2 = taintestindex[vari + '_trainindex2'][lay1, lay2, :]\n",
    "                testindex2 = taintestindex[vari + '_testindex2'][lay1, lay2, :]\n",
    "                stndata_trainl2 = stndata[trainindex2, :]\n",
    "                stndata_testl2 = stndata[testindex2, :]\n",
    "                stnlle_trainl2 = stnlle[trainindex2, :]\n",
    "                stnlle_testl2 = stnlle[testindex2, :]\n",
    "\n",
    "                for rr in range(reanum):\n",
    "                    # print('Correction/Merging at station points. Reanalysis:', rr)\n",
    "                    readata_trainl2 = readata_stn[rr, trainindex2, :]\n",
    "                    readata_testl2 = readata_stn[rr, testindex2, :]\n",
    "\n",
    "                    ### calculate corrected reanalysis data\n",
    "                    # calculate anomaly at the train stations\n",
    "                    anom_ori = calculate_anomaly(readata_trainl2, stndata_trainl2, hwsize, corrmode,\n",
    "                                                 upbound=anombound[1], lowbound=anombound[0])\n",
    "                    # extrapolate the ratio to the test stations\n",
    "                    anom_ext = extrapolation(anom_ori, nearstn_locl2[lay1,lay2,:],nearstn_distl2[lay1,lay2,:])\n",
    "                    # correct data at the test stations\n",
    "                    readata_testl2_corr = error_correction(readata_testl2, anom_ext, mode=corrmode)\n",
    "                    tf, index = ismember(testindex2, trainindex1)\n",
    "                    reacorr_trainl1[rr, index, :] = readata_testl2_corr\n",
    "\n",
    "            if weightmode == 'BMA':\n",
    "                for i in range(len(trainindex1)):\n",
    "                    dobs = stndata_trainl1[i, :]\n",
    "                    drea = reacorr_trainl1[:, i, :].T\n",
    "                    if var == 'prcp':\n",
    "                        # exclude zero precipitation and carry out box-cox transformation\n",
    "                        datatemp = np.zeros([ntimes,reanum+1])\n",
    "                        datatemp[:,0] = dobs\n",
    "                        datatemp[:,1:] = drea\n",
    "                        ind0 = np.sum(datatemp>=0.01, axis=1) == (reanum+1) # positive hit events\n",
    "                        if np.sum(ind0) < 10:\n",
    "                            weight_trainl1[i, :] = np.ones(reanum)/reanum\n",
    "                            continue\n",
    "                        else:\n",
    "                            dobs = box_cox_transform(dobs[ind0])\n",
    "                            drea = box_cox_transform(drea[ind0,:])\n",
    "                    w, sigma, sigma_s = bma(drea, dobs)\n",
    "                    weight_trainl1[i, :] = w\n",
    "            else:\n",
    "                for rr in range(reanum):\n",
    "                    weight_trainl1[:, rr] = calweight(stndata_trainl1, reacorr_trainl1[rr, :, :], weightmode)\n",
    "\n",
    "            np.savez_compressed(file_reacorrl1, reacorr=reacorr_trainl1, stnlle=stnlle_trainl1,\n",
    "                                reaweight=weight_trainl1)\n",
    "            # layer-2: end\n",
    "\n",
    "\n",
    "        # output: repeat error correction using train stations in layer-1 (as in layer-2 only 0.9*0.9=0.81 stations are used)\n",
    "        # extrapolate from train stations to test stations\n",
    "        for rr in range(reanum):\n",
    "            readata_trainl1 = readata_stn[rr, trainindex1, :]\n",
    "            readata_testl1 = readata_stn[rr, testindex1, :]\n",
    "            anom_ori = calculate_anomaly(readata_trainl1, stndata_trainl1, hwsize, corrmode,\n",
    "                                         upbound=anombound[1], lowbound=anombound[0])\n",
    "            anom_ext = extrapolation(anom_ori, nearstn_locl1[lay1,:],nearstn_distl1[lay1,:])\n",
    "            readata_testl1_corr = error_correction(readata_testl1, anom_ext, mode=corrmode)\n",
    "            reacorr_stn[rr, testindex1, :] = readata_testl1_corr\n",
    "\n",
    "        # output: extrapolate the weight from train stations to test stations (in layer-1)\n",
    "        weight_testl1 = extrapolation(weight_trainl1, nearstn_locl1[lay1,:],nearstn_distl1[lay1,:])\n",
    "        reamerge_weight_stn[testindex1, :] = weight_testl1\n",
    "\n",
    "        # output: merge reanalysis products at the test stations\n",
    "        nstn_testl1 = len(testindex1)\n",
    "        mergedata_testl1 = np.nan * np.zeros([nstn_testl1, ntimes])\n",
    "        for i in range(ntimes):\n",
    "            datain = np.zeros([nstn_testl1, reanum], dtype=np.float32)\n",
    "            for rr in range(reanum):\n",
    "                datain[:, rr] = reacorr_stn[rr, testindex1, i]\n",
    "            if var == 'prcp':\n",
    "                datain = box_cox_transform(datain)\n",
    "            dataout = weightmerge(datain, weight_testl1)\n",
    "            if var == 'prcp':\n",
    "                dataout = box_cox_recover(dataout)\n",
    "            mergedata_testl1[:, i] = dataout\n",
    "        reamerge_stn[testindex1, :] = mergedata_testl1\n",
    "\n",
    "    weightsum = np.nansum(reamerge_weight_stn,axis=1)\n",
    "    weightsum[weightsum==0] = np.nan\n",
    "    for rr in range(reanum):\n",
    "        reamerge_weight_stn[:, rr] = reamerge_weight_stn[:, rr] / weightsum\n",
    "    return reamerge_stn, reamerge_weight_stn, reacorr_stn\n",
    "\n",
    "\n",
    "def correct_merge(stndata, readata_raw, readata_stn, reacorr_stn, reamerge_stn, reamerge_weight_stn, neargrid_loc,\n",
    "         neargrid_dist, merge_choice, mask, hwsize, corrmode, anombound, var, weightmode):\n",
    "\n",
    "    nrows, ncols, nearnum = np.shape(neargrid_loc)\n",
    "    reanum, nstn, nday = np.shape(readata_stn)\n",
    "\n",
    "    neargrid_loc = neargrid_loc.copy()\n",
    "    neargrid_dist = neargrid_dist.copy()\n",
    "    mask2 = np.tile(mask[:,:,np.newaxis], (1,1,nearnum))\n",
    "    neargrid_loc[mask2 != 1] = -1\n",
    "    neargrid_dist[mask2 != 1] = np.nan\n",
    "    del mask2\n",
    "\n",
    "\n",
    "    # correct raw gridded reanalysis data using all stations\n",
    "    corr_data = np.nan * np.zeros([reanum, nrows, ncols, nday], dtype=np.float32)\n",
    "    for rr in range(reanum):\n",
    "        # calculate correction ratio at all station point\n",
    "        anom_ori = calculate_anomaly(readata_stn[rr, :, :], stndata[:, :],\n",
    "                                     hwsize, corrmode, upbound=anombound[1], lowbound=anombound[0])\n",
    "        anom_ext = extrapolation(anom_ori, neargrid_loc, neargrid_dist)\n",
    "        corr_data[rr, :, :, :] = error_correction(readata_raw[rr,:,:,:], anom_ext, mode=corrmode)\n",
    "\n",
    "    # first error estimation\n",
    "    corr_error = np.nan * np.zeros([reanum, nrows, ncols, nday])\n",
    "    for rr in range(reanum):\n",
    "        corr_error[rr, :, :, :] = extrapolation(reacorr_stn[rr, :, :] - stndata, neargrid_loc, neargrid_dist)\n",
    "    merge_error0 = extrapolation(reamerge_stn - stndata, neargrid_loc, neargrid_dist)\n",
    "\n",
    "    if var == 'prcp' and weightmode == 'BMA':\n",
    "        corr_data = box_cox_transform(corr_data)\n",
    "        stndata = box_cox_transform(stndata)\n",
    "        reamerge_stn = box_cox_transform(reamerge_stn)\n",
    "        reacorr_stn = box_cox_transform(reacorr_stn)\n",
    "\n",
    "        # correction error in normal space (box-cox)\n",
    "        corr_error_bc = np.nan * np.zeros([reanum, nrows, ncols, nday])\n",
    "        for rr in range(reanum):\n",
    "            corr_error_bc[rr, :, :, :] = extrapolation(reacorr_stn[rr, :, :] - stndata, neargrid_loc, neargrid_dist)\n",
    "        merge_error0_bc = extrapolation(reamerge_stn - stndata, neargrid_loc, neargrid_dist)\n",
    "\n",
    "    # merge reanalysis data\n",
    "    merge_data = np.nan * np.zeros([nrows, ncols, nday], dtype=np.float32)\n",
    "    weight_grid = extrapolation(reamerge_weight_stn, neargrid_loc, neargrid_dist)\n",
    "    for i in range(nday):\n",
    "        datain = np.zeros([nrows, ncols, reanum])\n",
    "        for rr in range(reanum):\n",
    "            datain[:, :, rr] = corr_data[rr, :, :, i]\n",
    "        merge_data[:, :, i] = weightmerge(datain, weight_grid)\n",
    "\n",
    "    # calculate the error of merged data (this is actually independent with merged data estimation)\n",
    "    merge_error = np.nan * np.zeros([nrows, ncols, nday], dtype=np.float32)\n",
    "    for r in range(nrows):\n",
    "        for c in range(ncols):\n",
    "            if not np.isnan(mask[r, c]):\n",
    "                chi = merge_choice[r, c]\n",
    "                if chi > 0:\n",
    "                    merge_error[r, c, :] = corr_error[chi - 1, r, c, :]\n",
    "                else:\n",
    "                    merge_error[r, c, :] = merge_error0[r, c, :]\n",
    "\n",
    "    if var == 'prcp' and weightmode == 'BMA':\n",
    "        merge_error_bc = np.nan * np.zeros([nrows, ncols, nday], dtype=np.float32)\n",
    "        for r in range(nrows):\n",
    "            for c in range(ncols):\n",
    "                if not np.isnan(mask[r, c]):\n",
    "                    chi = merge_choice[r, c]\n",
    "                    if chi > 0:\n",
    "                        merge_error_bc[r, c, :] = corr_error_bc[chi - 1, r, c, :]\n",
    "                    else:\n",
    "                        merge_error_bc[r, c, :] = merge_error0_bc[r, c, :]\n",
    "\n",
    "    if var == 'prcp' and weightmode == 'BMA':\n",
    "        merge_error_out = [''] * 2\n",
    "        merge_error_out[0] = merge_error\n",
    "        merge_error_out[1] = merge_error_bc\n",
    "        merge_data = box_cox_recover(merge_data)\n",
    "    else:\n",
    "        merge_error_out = ['']\n",
    "        merge_error_out[0] = merge_error\n",
    "    return corr_data, corr_error, merge_data, merge_error_out\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# var = sys.argv[1]\n",
    "# weightmode = sys.argv[2]\n",
    "\n",
    "########################################################################################################################\n",
    "var = 'prcp'  # ['prcp', 'tmean', 'trange']: this should be input from sbtach script\n",
    "weightmode = 'RMSE'  # (CC, RMSE, BMA). Weight = CC**2, or Weight = 1/RMSE**2, or Weight = BMA\n",
    "# basic settings\n",
    "lontar = np.arange(-180 + 0.05, -50, 0.1)\n",
    "lattar = np.arange(85 - 0.05, 5, -0.1)\n",
    "hwsize = 0  # define time window (2*hwsize+1) used to calculate ratio (as ratio for a specific day is too variable)\n",
    "nearnum = 8  # the number of nearby stations used to extrapolate points to grids (for correction and merging)\n",
    "dividenum = 10  # divide the datasets into X parts, e.g. 10-fold cross-validation\n",
    "anombound = [0.2, 5]  # upper and lower bound when calculating the anomaly for correction\n",
    "year = [2000, 2000]  # year range for merging. note weight is calculated using all data not limited by year\n",
    "\n",
    "# input files\n",
    "# station list and data\n",
    "# gmet_stnfile = '/home/gut428/GMET/eCAI_EMDNA/StnGridInfo/stnlist_whole.txt'\n",
    "# gmet_stndatafile = '/home/gut428/stndata_whole.npz'\n",
    "gmet_stnfile = '/Users/localuser/GMET/pyGMET_NA/stnlist_whole.txt'\n",
    "gmet_stndatafile = '/Users/localuser/GMET/pyGMET_NA/stndata_whole.npz'  # to be saved. only process when absent\n",
    "\n",
    "# mask file\n",
    "# file_mask = '/datastore/GLOBALWATER/CommonData/EMDNA/DEM/NA_DEM_010deg_trim.mat'\n",
    "file_mask = './DEM/NA_DEM_010deg_trim.mat'\n",
    "\n",
    "# downscaled reanalysis: gridded data\n",
    "prefix = ['ERA5_', 'MERRA2_', 'JRA55_']\n",
    "# downscaled reanalysis data at station points\n",
    "# path_readowngrid = ['/datastore/GLOBALWATER/CommonData/EMDNA/ERA5_day_ds',\n",
    "#                    '/datastore/GLOBALWATER/CommonData/EMDNA/MERRA2_day_ds',\n",
    "#                    '/datastore/GLOBALWATER/CommonData/EMDNA/JRA55_day_ds']\n",
    "# file_readownstn = ['/datastore/GLOBALWATER/CommonData/EMDNA/ERA5_day_ds/ERA5_downto_stn.npz',\n",
    "#                    '/datastore/GLOBALWATER/CommonData/EMDNA/MERRA2_day_ds/MERRA2_downto_stn.npz',\n",
    "#                    '/datastore/GLOBALWATER/CommonData/EMDNA/JRA55_day_ds/JRA55_downto_stn.npz']\n",
    "path_readowngrid = ['/Users/localuser/Research/Test',\n",
    "                   '/Users/localuser/Research/Test',\n",
    "                   '/Users/localuser/Research/Test']\n",
    "file_readownstn = ['/Users/localuser/Research/Test/ERA5_downto_stn.npz',\n",
    "                   '/Users/localuser/Research/Test/MERRA2_downto_stn.npz',\n",
    "                   '/Users/localuser/Research/Test/JRA55_downto_stn.npz']\n",
    "\n",
    "# output files\n",
    "# train and test index file\n",
    "ttindexfile = '/Users/localuser/Research/Test/2layer_train_test_index.npz'\n",
    "# ttindexfile = '/datastore/GLOBALWATER/CommonData/EMDNA/ReanalysisCorrMerge/CrossValidate_2layer/2layer_train_test_index.npz'\n",
    "\n",
    "# near stations\n",
    "near_path = '/Users/localuser/Research/Test'\n",
    "# near_path = '/home/gut428/ReanalysisCorrMerge'\n",
    "near_file_GMET = '/Users/localuser/GMET/pyGMET_NA/weight_nearstn.npz'\n",
    "# near_file_GMET = '/datastore/GLOBALWATER/CommonData/EMDNA/PyGMETout/weight.npz'\n",
    "useGMET = False\n",
    "\n",
    "# error and merging at station level\n",
    "path_reastn_cv = '/Users/localuser/Research/Test'\n",
    "# path_reastn_cv = '/datastore/GLOBALWATER/CommonData/EMDNA/ReanalysisCorrMerge/CrossValidate_2layer'\n",
    "file_corrmerge_stn = path_reastn_cv + '/mergecorr_' + var + '_' + weightmode + '.npz'\n",
    "\n",
    "# output corrected and merged data\n",
    "path_reacorr = '/Users/localuser/Research/Test'\n",
    "path_merge = '/Users/localuser/Research/Test'\n",
    "# path_reacorr = '/home/gut428/ReanalysisCorrMerge/Reanalysis_corr'\n",
    "# path_merge = '/home/gut428/ReanalysisCorrMerge/Reanalysis_merge'\n",
    "file_mergechoice = path_merge + '/mergechoice_' + var + '_' +  weightmode + '.npz'\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# basic processing\n",
    "print('start basic processing')\n",
    "# decide correction mode according to variables\n",
    "if var == 'prcp' or var == 'trange':\n",
    "    corrmode = 'ratio'  # ratio or diff: mode for error correction\n",
    "elif var == 'tmean':\n",
    "    corrmode = 'diff'\n",
    "else:\n",
    "    sys.exit('Unknown correction mode')\n",
    "\n",
    "if corrmode == 'diff':\n",
    "    # default settings in this study since diff is for tmean and trange\n",
    "    hwsize = 0\n",
    "    anombound = [-999, 999]\n",
    "\n",
    "# mask\n",
    "mask = io.loadmat(file_mask)\n",
    "mask = mask['DEM']\n",
    "mask[~np.isnan(mask)] = 1  # 1: valid pixels\n",
    "# attributes\n",
    "reanum = len(file_readownstn)\n",
    "nrows, ncols = np.shape(mask)\n",
    "lontarm, lattarm = np.meshgrid(lontar, lattar)\n",
    "lontarm[np.isnan(mask)] = np.nan\n",
    "lattarm[np.isnan(mask)] = np.nan\n",
    "\n",
    "# date\n",
    "date_list, date_number = m_DateList(1979, 2018, 'ByYear')\n",
    "\n",
    "# load observations for all stations\n",
    "datatemp = np.load(gmet_stndatafile)\n",
    "stndata = datatemp[var + '_stn']\n",
    "stnlle = datatemp['stn_lle']\n",
    "nstn, ntimes = np.shape(stndata)\n",
    "del datatemp\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# design a two-layer cross-validation: generate station combinations\n",
    "# index1 extracts 90% stations for merging and 10% stations for validation\n",
    "# index2 divides the 90% from index1 into 90% and 10% again for error correction\n",
    "if not os.path.isfile(ttindexfile):\n",
    "    print('divide stations for 2-layer cross validation')\n",
    "    prcp_trainindex1, prcp_testindex1, prcp_trainindex2, prcp_testindex2, \\\n",
    "    tmean_trainindex1, tmean_testindex1, tmean_trainindex2, tmean_testindex2 = \\\n",
    "        double_cvindex(gmet_stndatafile, dividenum, rndseed=123)\n",
    "    np.savez_compressed(ttindexfile, prcp_trainindex1=prcp_trainindex1, prcp_testindex1=prcp_testindex1,\n",
    "                        prcp_trainindex2=prcp_trainindex2, prcp_testindex2=prcp_testindex2,\n",
    "                        tmean_trainindex1=tmean_trainindex1, tmean_testindex1=tmean_testindex1,\n",
    "                        tmean_trainindex2=tmean_trainindex2, tmean_testindex2=tmean_testindex2)\n",
    "    del prcp_trainindex1, prcp_testindex1, prcp_trainindex2, prcp_testindex2, \\\n",
    "        tmean_trainindex1, tmean_testindex1, tmean_trainindex2, tmean_testindex2\n",
    "\n",
    "taintestindex = np.load(ttindexfile)\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# find near stations for all grids and station\n",
    "\n",
    "if var == 'trange':\n",
    "    vari = 'tmean'  # trange and tmean have the same index\n",
    "else:\n",
    "    vari = var\n",
    "\n",
    "near_stnfile = near_path + '/near_stn_' + vari + '.npz'\n",
    "near_gridfile = near_path + '/near_grid_' + vari + '.npz'\n",
    "\n",
    "if os.path.isfile(near_stnfile):\n",
    "    print('load near station information for points')\n",
    "    with np.load(near_stnfile) as datatemp:\n",
    "        nearstn_locl1 = datatemp['nearstn_locl1']\n",
    "        nearstn_distl1 = datatemp['nearstn_distl1']\n",
    "        nearstn_locl2 = datatemp['nearstn_locl2']\n",
    "        nearstn_distl2 = datatemp['nearstn_distl2']\n",
    "    del datatemp\n",
    "else:\n",
    "    print('find near stations for station points')\n",
    "    # layer-1\n",
    "    nstn_testl1 = np.shape(taintestindex[vari + '_testindex1'])[1]\n",
    "    nearstn_locl1 = -1 * np.ones([dividenum, nstn_testl1, nearnum], dtype=int)\n",
    "    nearstn_distl1 = -1 * np.ones([dividenum, nstn_testl1, nearnum], dtype=np.float32)\n",
    "    for lay1 in range(dividenum):\n",
    "        trainindex1 = taintestindex[vari + '_trainindex1'][lay1, :]\n",
    "        testindex1 = taintestindex[vari + '_testindex1'][lay1, :]\n",
    "        nearstn_locl1[lay1, :, :], nearstn_distl1[lay1, :, :] \\\n",
    "            = findnearstn(stnlle[trainindex1, 0], stnlle[trainindex1, 1],\n",
    "                          stnlle[testindex1, 0], stnlle[testindex1, 1], nearnum, 0)\n",
    "    # layer-2\n",
    "    nstn_testl2 = np.shape(taintestindex[vari + '_testindex2'])[2]\n",
    "    nearstn_locl2 = -1 * np.ones([dividenum, dividenum, nstn_testl2, nearnum], dtype=int)\n",
    "    nearstn_distl2 = -1 * np.ones([dividenum, dividenum, nstn_testl2, nearnum], dtype=np.float32)\n",
    "    for lay1 in range(dividenum):\n",
    "        for lay2 in range(dividenum):\n",
    "            trainindex2 = taintestindex[vari + '_trainindex2'][lay1, lay2, :]\n",
    "            testindex2 = taintestindex[vari + '_testindex2'][lay1, lay2, :]\n",
    "            nearstn_locl2[lay1, lay2, :, :], nearstn_distl2[lay1, lay2, :, :] \\\n",
    "                = findnearstn(stnlle[trainindex2, 0], stnlle[trainindex2, 1],\n",
    "                              stnlle[testindex2, 0], stnlle[testindex2, 1], nearnum, 0)\n",
    "\n",
    "    np.savez_compressed(near_stnfile, nearstn_locl1=nearstn_locl1, nearstn_distl1=nearstn_distl1,\n",
    "                        nearstn_locl2=nearstn_locl2, nearstn_distl2=nearstn_distl2)\n",
    "\n",
    "if os.path.isfile(near_gridfile):\n",
    "    print('load near station information for grids')\n",
    "    with np.load(near_gridfile) as datatemp:\n",
    "        neargrid_loc = datatemp['neargrid_loc']\n",
    "        neargrid_dist = datatemp['neargrid_dist']\n",
    "else:\n",
    "    print('find near stations for grids')\n",
    "    stnlle_in = stnlle.copy()\n",
    "    stnlle_in[np.isnan(stndata[:, 0]), 0:2] = np.nan\n",
    "    neargrid_loc, neargrid_dist = findnearstn(stnlle_in[:, 0], stnlle_in[:, 1], lattarm, lontarm, nearnum, 0)\n",
    "    np.savez_compressed(near_gridfile,neargrid_loc=neargrid_loc,neargrid_dist=neargrid_dist)\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# load downscaled reanalysis for all stations\n",
    "print('load downscaled reanalysis data at station points')\n",
    "readata_stn = np.nan * np.zeros([reanum, nstn, ntimes], dtype=np.float32)\n",
    "for rr in range(reanum):\n",
    "    dr = np.load(file_readownstn[rr])\n",
    "    temp = dr[var + '_readown']\n",
    "    if prefix[rr] == 'MERRA2_':  # unify the time length of all data as MERRA2 lacks 1979\n",
    "        add = np.nan * np.zeros([nstn, 365])\n",
    "        temp = np.concatenate((add, temp), axis=1)\n",
    "    readata_stn[rr, :, :] = temp\n",
    "    del dr, temp\n",
    "if var == 'prcp':\n",
    "    readata_stn[readata_stn<0] = 0\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# estimate the error of corrected and merged data at station points using cross-validation\n",
    "# target outputs: weights for merging, merge choice, error of the merged dataset\n",
    "# 0. load regression estimates and observations for all stations\n",
    "# 1. select layer-1 stations (90% train, 10% test)\n",
    "# 2. select layer-2 stations: 10 combinations (90% train, 10% test) from the 90% stations in layer-1\n",
    "# 3. for all combinations in layer-2\n",
    "# 3.1 perform error correction (1) at station points, (2) extrapolate to grids using training stations\n",
    "# 3.2 perform evaluation using test stations\n",
    "# 3.3 loop for all combinations and do evaluation at all stations (the 90% training stations from layer-1)\n",
    "# 3.4 extrapolate evaluation accuracy indicators to the domain\n",
    "# 4. merge three reanalysis using their indicators in 3.4\n",
    "# 5. repeat 1-4 for all combinations in layer-1, and get accuracy indicators of the merged dataset for the domain\n",
    "# 6. use indicators from 3.4 and 5, and select the best one among three reanalysis and merged datasets for each grid\n",
    "# 7. get the final merged dataset and its accuracy indicators from steo-6\n",
    "\n",
    "# get merged and corrected reanalysis data at all station points using two-layer cross-validation\n",
    "if os.path.isfile(file_corrmerge_stn):\n",
    "    print('load independent merged/corrected data at station points')\n",
    "    datatemp = np.load(file_corrmerge_stn)\n",
    "    reamerge_stn = datatemp['reamerge_stn']\n",
    "    reamerge_weight_stn = datatemp['reamerge_weight_stn']\n",
    "    reacorr_stn = datatemp['reacorr_stn']\n",
    "    del datatemp\n",
    "else:\n",
    "    reamerge_stn = np.nan * np.zeros([nstn, ntimes], dtype=np.float32)\n",
    "    reamerge_weight_stn = np.nan * np.zeros([12, nstn, reanum], dtype=np.float32)\n",
    "    reacorr_stn = np.nan * np.zeros([reanum, nstn, ntimes], dtype=np.float32)\n",
    "    # for each month\n",
    "    for m in range(12):\n",
    "        print('month', m+1)\n",
    "        outpathm = path_reastn_cv + '/month_' + str(m + 1)\n",
    "        if not os.path.isdir(outpathm):\n",
    "            os.mkdir(outpathm)\n",
    "        indm = date_number['mm'] == (m + 1)\n",
    "        reamerge_stnm, reamerge_weight_stnm, reacorr_stnm = \\\n",
    "            merge_correction_stnerror(outpathm, stnlle, stndata[:,indm], readata_stn[:,:,indm], taintestindex,\n",
    "                                      nearstn_locl1, nearstn_distl1, nearstn_locl2, nearstn_distl2,\n",
    "                                      dividenum, var, hwsize, corrmode, anombound, weightmode)\n",
    "        reamerge_stn[:, indm] = reamerge_stnm\n",
    "        reacorr_stn[:, :, indm] = reacorr_stnm\n",
    "        reamerge_weight_stn[m, :, :] = reamerge_weight_stnm\n",
    "    # the variables are independent with their concurrent stations. thus, station data can be used to evaluate them\n",
    "    np.savez_compressed(file_corrmerge_stn, reamerge_stn=reamerge_stn, reamerge_weight_stn=reamerge_weight_stn,\n",
    "                        reacorr_stn=reacorr_stn, date_list=date_list)\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# which is the best for each grid (all reanalysis and the merged reanalysis)\n",
    "if os.path.isfile(file_mergechoice):\n",
    "    print('load merge choice file')\n",
    "    datatemp = np.load(file_mergechoice)\n",
    "    merge_choice = datatemp['merge_choice']\n",
    "    del datatemp\n",
    "else:\n",
    "    print('determine the best data choice for each grid cell')\n",
    "    merge_choice = -1 * np.zeros([12,nrows,ncols], dtype=int)\n",
    "    for m in range(12):\n",
    "        print('month', m+1)\n",
    "        indm = date_number['mm'] == (m + 1)\n",
    "        # evaluate merge and corrected reanalysis\n",
    "        # this evaluation is feasible as merge or corrected data are all obtained using independent stations\n",
    "        met_merge_stn = calmetric(reamerge_stn[:, indm], stndata[:, indm], metname='RMSE')\n",
    "        met_corr_stn = np.nan * np.zeros([nstn, reanum])\n",
    "        for rr in range(reanum):\n",
    "            met_corr_stn[:, rr] = calmetric(reacorr_stn[rr][ :, indm], stndata[:, indm], metname='RMSE')\n",
    "\n",
    "        metric_all = np.zeros([nrows, ncols, reanum + 1])\n",
    "        met_merge_grid = extrapolation(met_merge_stn, neargrid_loc, neargrid_dist)\n",
    "        met_corr_grid = extrapolation(met_corr_stn, neargrid_loc, neargrid_dist)\n",
    "        metric_all[:, :, 0] = met_merge_grid\n",
    "        metric_all[:, :, 1:] = met_corr_grid\n",
    "        merge_choicem = np.argmax(metric_all, axis=2)  # 0: merge, 1 to N: corresponding corrected reanalysis\n",
    "        merge_choicem[mask != 1] = -1\n",
    "        merge_choice[m, :, :] = merge_choicem\n",
    "        del metric_all, met_merge_grid, met_corr_grid\n",
    "    np.savez_compressed(file_mergechoice, merge_choice=merge_choice)\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# final merging with data and error\n",
    "\n",
    "# use the same weight with GMET estimation?\n",
    "if useGMET == True:\n",
    "    print('use near station information from GMET regression')\n",
    "    del neargrid_loc, neargrid_dist\n",
    "    datatemp = np.load(near_file_GMET)\n",
    "    if var == 'prcp':\n",
    "        neargrid_loc = datatemp['near_grid_prcpLoc']\n",
    "        neargrid_dist = datatemp['near_grid_prcpDist']\n",
    "    else:\n",
    "        neargrid_loc = datatemp['near_grid_tempDist']\n",
    "        neargrid_dist = datatemp['near_grid_tempDist']\n",
    "    neargrid_loc = np.flipud(neargrid_loc)\n",
    "    neargrid_dist = np.flipud(neargrid_dist)\n",
    "\n",
    "# start ...\n",
    "for y in range(year[0], year[1] + 1):\n",
    "    print('Correction and Merge: year',y)\n",
    "    filemerge = path_merge + 'mergedata_' + var + '_' + str(y) + weightmode + '.npz'\n",
    "    filecorr = path_reacorr + 'reacorrdata_' + var + '_' + str(y) + '.npz'\n",
    "    if os.path.isfile(filemerge) and os.path.isfile(filecorr):\n",
    "        print('file exists ... continue')\n",
    "        continue\n",
    "\n",
    "    # initilization\n",
    "    nday = np.sum(date_number['yyyy'] == y)\n",
    "    corr_data = np.nan * np.zeros([reanum, nrows, ncols, nday], dtype=np.float32)\n",
    "    corr_error = np.nan * np.zeros([reanum, nrows, ncols, nday], dtype=np.float32)\n",
    "    merge_data = np.nan * np.zeros([nrows, ncols, nday], dtype=np.float32)\n",
    "    merge_error = np.nan * np.zeros([nrows, ncols, nday], dtype=np.float32)\n",
    "    if var == 'prcp' and weightmode == 'BMA':\n",
    "        merge_error_bc = np.nan * np.zeros([nrows, ncols, nday], dtype=np.float32) # error in normal space (box-cox)\n",
    "\n",
    "    # read raw gridded reanalysis data\n",
    "    readata_raw = np.nan * np.zeros([reanum, nrows, ncols, nday], dtype=np.float32)\n",
    "    for rr in range(reanum):\n",
    "        if not (prefix[rr] == 'MERRA2_' and y == 1979):\n",
    "            filer = path_readowngrid[rr] + '/' + prefix[rr] + var + '_' + str(y) + '.npz'\n",
    "            d = np.load(filer)\n",
    "            readata_raw[rr, :, :, :] = d['data']\n",
    "            del d\n",
    "\n",
    "    # process for each month\n",
    "    for m in range(12):\n",
    "        print('Correction and Merge: month', m+1)\n",
    "        indym = (date_number['yyyy'] == y) & (date_number['mm'] == m+1)\n",
    "        ym = date_number['mm'][date_number['yyyy'] == y]\n",
    "        indm = ym == m+1\n",
    "\n",
    "        corr_datam, corr_errorm, merge_datam, merge_errorm = \\\n",
    "            correct_merge(stndata[:, indym], readata_raw[:,:,:,indm], readata_stn[:, :, indym], reacorr_stn[:, :, indym],\n",
    "                          reamerge_stn[:, indym], reamerge_weight_stn[m, :, :], neargrid_loc, neargrid_dist,\n",
    "                          merge_choice[m, :, :], mask, hwsize, corrmode, anombound, var, weightmode)\n",
    "        corr_data[:,:,:,indm] = corr_datam\n",
    "        corr_error[:, :, :, indm] = corr_errorm\n",
    "        merge_data[:, :, indm] = merge_datam\n",
    "        merge_error[:, :, indm] = merge_errorm[0]\n",
    "        if var == 'prcp' and weightmode == 'BMA':\n",
    "            merge_error_bc[:, :, indm] = merge_errorm[1]\n",
    "\n",
    "    np.savez_compressed(filecorr, corr_data=corr_data, corr_error=corr_error,\n",
    "                        reaname=prefix, latitude=lattar, longitude=lontar)\n",
    "    if var == 'prcp' and weightmode == 'BMA':\n",
    "        np.savez_compressed(filemerge, merge_data=merge_data, merge_error=merge_error, merge_error_bc=merge_error_bc,\n",
    "                            latitude=lattar, longitude=lontar, reaname=prefix)\n",
    "    else:\n",
    "        np.savez_compressed(filemerge, merge_data=merge_data, merge_error=merge_error,\n",
    "                            latitude=lattar, longitude=lontar, reaname=prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use near station information from GMET regression\n",
      "Correction and Merge: year 2000\n",
      "Correction and Merge: month 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: Mean of empty slice\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:95: RuntimeWarning: Mean of empty slice\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:98: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:98: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:106: RuntimeWarning: invalid value encountered in greater\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:107: RuntimeWarning: invalid value encountered in less\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:284: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correction and Merge: month 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-191-1b9e9631058e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mcorr_datam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorr_errorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_datam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_errorm\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             correct_merge(stndata[:, indym], readata_raw[:,:,:,indm], readata_stn[:, :, indym], reacorr_stn[:, :, indym],\n\u001b[0m\u001b[1;32m     51\u001b[0m                           \u001b[0mreamerge_stn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindym\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreamerge_weight_stn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneargrid_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneargrid_dist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                           merge_choice[m, :, :], mask, hwsize, corrmode, anombound, var, weightmode)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "useGMET=True\n",
    "if useGMET == True:\n",
    "    print('use near station information from GMET regression')\n",
    "    del neargrid_loc, neargrid_dist\n",
    "    datatemp = np.load(near_file_GMET)\n",
    "    if var == 'prcp':\n",
    "        neargrid_loc = datatemp['near_grid_prcpLoc']\n",
    "        neargrid_dist = datatemp['near_grid_prcpDist']\n",
    "    else:\n",
    "        neargrid_loc = datatemp['near_grid_tempDist']\n",
    "        neargrid_dist = datatemp['near_grid_tempDist']\n",
    "    neargrid_loc = np.flipud(neargrid_loc)\n",
    "    neargrid_dist = np.flipud(neargrid_dist)\n",
    "\n",
    "# start ...\n",
    "for y in range(year[0], year[1] + 1):\n",
    "    print('Correction and Merge: year',y)\n",
    "    filemerge = path_merge + 'mergedata_' + var + '_' + str(y) + weightmode + '.npz'\n",
    "    filecorr = path_reacorr + 'reacorrdata_' + var + '_' + str(y) + '.npz'\n",
    "    if os.path.isfile(filemerge) and os.path.isfile(filecorr):\n",
    "        print('file exists ... continue')\n",
    "        continue\n",
    "\n",
    "    # initilization\n",
    "    nday = np.sum(date_number['yyyy'] == y)\n",
    "    corr_data = np.nan * np.zeros([reanum, nrows, ncols, nday], dtype=np.float32)\n",
    "    corr_error = np.nan * np.zeros([reanum, nrows, ncols, nday], dtype=np.float32)\n",
    "    merge_data = np.nan * np.zeros([nrows, ncols, nday], dtype=np.float32)\n",
    "    merge_error = np.nan * np.zeros([nrows, ncols, nday], dtype=np.float32)\n",
    "    if var == 'prcp' and weightmode == 'BMA':\n",
    "        merge_error_bc = np.nan * np.zeros([nrows, ncols, nday], dtype=np.float32) # error in normal space (box-cox)\n",
    "\n",
    "    # read raw gridded reanalysis data\n",
    "    readata_raw = np.nan * np.zeros([reanum, nrows, ncols, nday], dtype=np.float32)\n",
    "    for rr in range(reanum):\n",
    "        if not (prefix[rr] == 'MERRA2_' and y == 1979):\n",
    "            filer = path_readowngrid[rr] + '/' + prefix[rr] + var + '_' + str(y) + '.npz'\n",
    "            d = np.load(filer)\n",
    "            readata_raw[rr, :, :, :] = d['data']\n",
    "            del d\n",
    "\n",
    "    # process for each month\n",
    "    for m in range(12):\n",
    "        print('Correction and Merge: month', m+1)\n",
    "        indym = (date_number['yyyy'] == y) & (date_number['mm'] == m+1)\n",
    "        ym = date_number['mm'][date_number['yyyy'] == y]\n",
    "        indm = ym == m+1\n",
    "\n",
    "        corr_datam, corr_errorm, merge_datam, merge_errorm = \\\n",
    "            correct_merge(stndata[:, indym], readata_raw[:,:,:,indm], readata_stn[:, :, indym], reacorr_stn[:, :, indym],\n",
    "                          reamerge_stn[:, indym], reamerge_weight_stn[m, :, :], neargrid_loc, neargrid_dist,\n",
    "                          merge_choice[m, :, :], mask, hwsize, corrmode, anombound, var, weightmode)\n",
    "        corr_data[:,:,:,indm] = corr_datam\n",
    "        corr_error[:, :, :, indm] = corr_errorm\n",
    "        merge_data[:, :, indm] = merge_datam\n",
    "        merge_error[:, :, indm] = merge_errorm[0]\n",
    "        if var == 'prcp' and weightmode == 'BMA':\n",
    "            merge_error_bc[:, :, indm] = merge_errorm[1]\n",
    "\n",
    "    np.savez_compressed(filecorr, corr_data=corr_data, corr_error=corr_error,\n",
    "                        reaname=prefix, latitude=lattar, longitude=lontar)\n",
    "    if var == 'prcp' and weightmode == 'BMA':\n",
    "        np.savez_compressed(filemerge, merge_data=merge_data, merge_error=merge_error, merge_error_bc=merge_error_bc,\n",
    "                            latitude=lattar, longitude=lontar, reaname=prefix)\n",
    "    else:\n",
    "        np.savez_compressed(filemerge, merge_data=merge_data, merge_error=merge_error,\n",
    "                            latitude=lattar, longitude=lontar, reaname=prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(merge_error[:,:,3])\n",
    "plt.colorbar()\n",
    "plt.clim([-3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5\n",
      "[[ 2.5 -0.5  2.5]\n",
      " [-0.5  1.3 -0.5]\n",
      " [ 2.5 -0.5  2.5]]\n"
     ]
    }
   ],
   "source": [
    "def cov(a, b):\n",
    "\n",
    "    if len(a) != len(b):\n",
    "        return\n",
    "\n",
    "    a_mean = np.mean(a)\n",
    "    b_mean = np.mean(b)\n",
    "\n",
    "    sum = 0\n",
    "\n",
    "    for i in range(0, len(a)):\n",
    "        sum += ((a[i] - a_mean) * (b[i] - b_mean))\n",
    "\n",
    "    return sum/(len(a)-1)\n",
    "\n",
    "a=np.arange(5)\n",
    "b=np.array([4,2,1,2,3])\n",
    "print(cov(a,b))\n",
    "print(np.cov((a,b,a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 0.0000000e+00],\n",
       "       [8.8817842e-16, 1.0000000e+00]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
