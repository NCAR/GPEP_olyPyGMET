{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year: [2018, 2018]\n"
     ]
    }
   ],
   "source": [
    "# merge background (reanalysis) and observation (regression estimates)\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import io\n",
    "import os\n",
    "import sys\n",
    "from optimal_interpolation import OImerge\n",
    "import calendar\n",
    "import auxiliary as au\n",
    "from auxiliary_merge import *\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# time periods and methods\n",
    "# y1 = int(sys.argv[1])\n",
    "# y2 = int(sys.argv[2])\n",
    "# vars = sys.argv[3]\n",
    "# vars = [vars]\n",
    "# month = int(sys.argv[4])\n",
    "# year = [y1, y2]\n",
    "\n",
    "\n",
    "y1 = 2018\n",
    "y2 = 2018\n",
    "vars = 'prcp'\n",
    "vars = [vars]\n",
    "month = 2\n",
    "year = [y1, y2]\n",
    "print('year:',year)\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# basic settings\n",
    "weightmode = 'BMA' # method used to merge different reanalysis products\n",
    "# vars = ['prcp', 'tmean', 'trange']\n",
    "hwsize = 2  # 5X5 space window used to support estimation at the center grid\n",
    "lontar = np.arange(-180 + 0.05, -50, 0.1)\n",
    "lattar = np.arange(85 - 0.05, 5, -0.1)\n",
    "\n",
    "# \"Gaussian\": prcp will be transformed into normal distributions; \"Actual\": actual space\n",
    "# \"Gaussian\" is not a good choice because station prcp regression using box-cox has large underestimation\n",
    "prcp_space = 'Actual'\n",
    "\n",
    "### Local Mac settings\n",
    "# input files/paths\n",
    "path_bac = '/Users/localuser/Research/EMDNA/merge' # data that will be used as background\n",
    "path_obs = '/Users/localuser/Research/EMDNA/regression' # data that will be used as observation\n",
    "near_file_GMET = '/Users/localuser/Research/EMDNA/regression/weight_nearstn.npz' # near station of stations/grids\n",
    "file_mask = './DEM/NA_DEM_010deg_trim.mat'\n",
    "FileStnInfo = '/Users/localuser/GMET/pyGMET_NA/stnlist_whole.txt'\n",
    "gmet_stndatafile = '/Users/localuser/Research/EMDNA/stndata_whole.npz'\n",
    "\n",
    "# output files/paths (can also be used as inputs once generated)\n",
    "path_oimerge = '/Users/localuser/Research/EMDNA/oimerge'\n",
    "\n",
    "### Local Mac settings\n",
    "\n",
    "\n",
    "# ### Plato settings\n",
    "# # input files/paths\n",
    "# path_bac = '/home/gut428/ReanalysisCorrMerge/Reanalysis_merge'\n",
    "# path_obs = '/datastore/GLOBALWATER/CommonData/EMDNA/PyGMETout'\n",
    "# near_file_GMET = '/datastore/GLOBALWATER/CommonData/EMDNA/PyGMETout/weight.npz'\n",
    "# file_mask = '/datastore/GLOBALWATER/CommonData/EMDNA/DEM/NA_DEM_010deg_trim.mat'\n",
    "# FileStnInfo = '/home/gut428/GMET/eCAI_EMDNA/StnGridInfo/stnlist_whole.txt'\n",
    "# gmet_stndatafile = '/datastore/GLOBALWATER/CommonData/EMDNA/stndata_whole.npz'\n",
    "#\n",
    "# # output files/paths (can also be used as inputs once generated)\n",
    "# path_oimerge = '/home/gut428/OImerge'\n",
    "# ### Plato settings\n",
    "\n",
    "file_regression_stn = path_obs + '/daily_regression_stn.npz'\n",
    "file_corrmerge_stn = [''] * len(vars)\n",
    "for i in range(len(vars)):\n",
    "    file_corrmerge_stn[i] = path_bac + '/mergecorr_stn_' + vars[i] + '_GWRQM_' + weightmode + '.npz'\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# basic processing\n",
    "mask = io.loadmat(file_mask)\n",
    "mask = mask['DEM']\n",
    "mask[~np.isnan(mask)] = 1  # 1: valid pixels\n",
    "nrows, ncols = np.shape(mask)\n",
    "\n",
    "# date\n",
    "date_list, date_number = m_DateList(2018, 2018, 'ByYear')\n",
    "\n",
    "# stninfo\n",
    "stnID, stninfo = au.readstnlist(FileStnInfo)\n",
    "nstn = len(stnID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OI merge at stations: prcp\n"
     ]
    }
   ],
   "source": [
    "for v in range(len(vars)):\n",
    "    print('OI merge at stations:', vars[v])\n",
    "\n",
    "    # load station original observations\n",
    "    datatemp = np.load(gmet_stndatafile)\n",
    "    observation_stn = datatemp[vars[v]+'_stn']\n",
    "\n",
    "    # load station regression estimates (obs)\n",
    "    datatemp = np.load(file_regression_stn)\n",
    "    regression_stn = datatemp[vars[v]]\n",
    "    del datatemp\n",
    "\n",
    "    # load corrected/merged reanalysis data at all station points (those are totally independent with station observations)\n",
    "    datatemp = np.load(file_corrmerge_stn[v])\n",
    "    reafinal_stn = datatemp['reamerge_stn']\n",
    "    nstn, ntimes = np.shape(reafinal_stn)\n",
    "    del datatemp\n",
    "\n",
    "    # load near station information\n",
    "    datatemp = np.load(near_file_GMET)\n",
    "    if vars[v] == 'prcp':\n",
    "        near_loc = datatemp['near_grid_prcpLoc']\n",
    "        near_weight = datatemp['near_grid_prcpWeight']\n",
    "        near_dist = datatemp['near_grid_prcpDist']\n",
    "    else:\n",
    "        near_loc = datatemp['near_grid_tempLoc']\n",
    "        near_weight = datatemp['near_grid_tempWeight']\n",
    "        near_dist = datatemp['near_grid_tempDist']\n",
    "    del datatemp\n",
    "\n",
    "    # load OI merged data at station points\n",
    "    filemerge_stn = path_oimerge + '/OImerge_stn_GWRQMBMA_' + vars[v] + '.npz'\n",
    "    datatemp = np.load(filemerge_stn)\n",
    "    oimerge_stn = datatemp['oimerge_stn']\n",
    "    del datatemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month 2\n",
      "load gridded merged data\n"
     ]
    }
   ],
   "source": [
    "    for m in range(month-1, month):\n",
    "        print('month', m + 1)\n",
    "        indm = (date_number['mm'] == m + 1)\n",
    "        nday = sum(indm)\n",
    "        datem = date_number['yyyy'][indm]\n",
    "\n",
    "        # load gridded merged reanalysis data for all years\n",
    "        print('load gridded merged data')\n",
    "        reagrid_value = np.nan * np.zeros([nrows, ncols, nday], dtype=np.float32)\n",
    "        reagrid_error = np.nan * np.zeros([nrows, ncols, nday], dtype=np.float32)\n",
    "        for y in range(2018, 2019):\n",
    "            indym = datem == y\n",
    "            filey = path_bac + '/bmamerge_' + vars[v] + '_' + str(y*100+m+1) + '.npz'\n",
    "            datatemp = np.load(filey)\n",
    "            reagrid_value[:, :, indym] = datatemp['bma_data']\n",
    "            reagrid_error[:, :, indym] = datatemp['bma_error']\n",
    "            del datatemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate OI merging weights\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d8f9c8b0a278>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# delete possible nan values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0minduse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_err_b\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnear_err_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnear_err_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOImerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_err_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minduse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnear_err_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minduse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnear_err_o\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minduse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meye_o\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0moiweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/PyGMET/optimal_interpolation.py\u001b[0m in \u001b[0;36mOImerge\u001b[0;34m(tar_err_b, near_err_b, near_err_o, eye_o)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# covariance matrix of errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mCb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnear_err_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mCo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnear_err_o\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meye_o\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcov\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights)\u001b[0m\n\u001b[1;32m   2429\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0maweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2431\u001b[0;31m     \u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2432\u001b[0m     \u001b[0mw_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_sum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36maverage\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m             \u001b[0mscl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbroadcast_to\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_to\u001b[0;34m(array, shape, subok)\u001b[0m\n\u001b[1;32m    180\u001b[0m            [1, 2, 3]])\n\u001b[1;32m    181\u001b[0m     \"\"\"\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_broadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_to\u001b[0;34m(array, shape, subok, readonly)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# never really has writebackifcopy semantics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mbroadcast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_view_as_subclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# In a future version this will go away\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "        date_list, date_number2 = m_DateList(1979, 2018, 'ByYear')\n",
    "        indm2 = (date_number2['mm'] == m+1) & (date_number2['yyyy']==2018)\n",
    "        # calculate OI-merging weights for every grids\n",
    "        print('calculate OI merging weights')\n",
    "        file_oiweight = path_oimerge + '/oiweight_' + vars[v] + '_month_' + str(m+1) + '.npz'\n",
    "        if os.path.isfile(file_oiweight):\n",
    "            datatemp = np.load(file_oiweight)\n",
    "            oiweight = datatemp['oiweight']\n",
    "            del datatemp\n",
    "        else:\n",
    "            oiweight = np.nan * np.zeros([nrows, ncols, np.shape(near_loc)[2]], dtype=np.float32)\n",
    "            for r in range(nrows):\n",
    "                if np.mod(r,10)==0:\n",
    "                    print(r)\n",
    "                for c in range(ncols):\n",
    "                    if np.isnan(mask[r, c]):\n",
    "                        continue\n",
    "                    near_loci = near_loc[r, c, :]\n",
    "                    near_loci = near_loci[near_loci > -1]\n",
    "\n",
    "                    b_near = reafinal_stn[near_loci, :][:, indm2]\n",
    "                    o_near = regression_stn[near_loci, :][:, indm2]\n",
    "                    tar_err_b = reagrid_error[r, c, :]\n",
    "                    near_err_b = b_near - observation_stn[near_loci, :][:, indm2]\n",
    "                    near_err_o = o_near - observation_stn[near_loci, :][:, indm2]\n",
    "\n",
    "                    # delete possible nan values\n",
    "                    induse = ~np.isnan(tar_err_b + np.sum(near_err_b, axis=0) + np.sum(near_err_o, axis=0))\n",
    "                    weight = OImerge(tar_err_b[induse], near_err_b[:, induse], near_err_o[:, induse], eye_o=0)\n",
    "\n",
    "                    oiweight[r, c, 0:len(weight)] = weight\n",
    "            np.savez_compressed(file_oiweight, oiweight=oiweight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oiweight[270,100,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
