{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year: [1980, 1980]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import io\n",
    "import os\n",
    "import sys\n",
    "from optimal_interpolation import OImerge\n",
    "import calendar\n",
    "import auxiliary as au\n",
    "from auxiliary_merge import *\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# time periods and methods\n",
    "# y1 = int(sys.argv[3])\n",
    "# y2 = int(sys.argv[4])\n",
    "# year = [y1, y2]\n",
    "year = [1980, 1980]\n",
    "print('year:',year)\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# basic settings\n",
    "weightmode = 'BMA' # method used to merge different reanalysis products\n",
    "vars = ['prcp', 'tmean', 'trange']\n",
    "hwsize = 2  # 5X5 space window used to support estimation at the center grid\n",
    "lontar = np.arange(-180 + 0.05, -50, 0.1)\n",
    "lattar = np.arange(85 - 0.05, 5, -0.1)\n",
    "\n",
    "# \"Gaussian\": prcp will be transformed into normal distributions; \"Actual\": actual space\n",
    "# \"Gaussian\" is not a good choice because station prcp regression using box-cox has large underestimation\n",
    "prcp_space = 'Actual'\n",
    "\n",
    "### Local Mac settings\n",
    "# input files/paths\n",
    "path_bac = '/Users/localuser/Research/EMDNA/merge' # data that will be used as background\n",
    "path_obs = '/Users/localuser/Research/EMDNA/regression' # data that will be used as observation\n",
    "near_file_GMET = '/Users/localuser/Research/EMDNA/regression/weight_nearstn.npz' # near station of stations/grids\n",
    "file_mask = './DEM/NA_DEM_010deg_trim.mat'\n",
    "FileStnInfo = '/Users/localuser/GMET/pyGMET_NA/stnlist_whole.txt'\n",
    "gmet_stndatafile = '/Users/localuser/Research/EMDNA/stndata_whole.npz'\n",
    "\n",
    "# output files/paths (can also be used as inputs once generated)\n",
    "path_oimerge = '/Users/localuser/Research/EMDNA/oimerge'\n",
    "\n",
    "### Local Mac settings\n",
    "\n",
    "\n",
    "# ### Plato settings\n",
    "# # input files/paths\n",
    "# path_bac = '/datastore/GLOBALWATER/CommonData/EMDNA/ReanalysisCorrMerge/Reanalysis_merge'\n",
    "# path_obs = '/datastore/GLOBALWATER/CommonData/EMDNA/PyGMETout'\n",
    "# near_file_GMET = '/datastore/GLOBALWATER/CommonData/EMDNA/PyGMETout/weight.npz'\n",
    "# file_mask = '/datastore/GLOBALWATER/CommonData/EMDNA/DEM/NA_DEM_010deg_trim.mat'\n",
    "# FileStnInfo = '/home/gut428/GMET/eCAI_EMDNA/StnGridInfo/stnlist_whole.txt'\n",
    "# gmet_stndatafile = '/datastore/GLOBALWATER/CommonData/EMDNA/stndata_whole.npz'\n",
    "\n",
    "# # output files/paths (can also be used as inputs once generated)\n",
    "# path_oimerge = '/home/gut428/OImerge'\n",
    "# ### Plato settings\n",
    "\n",
    "file_regression_stn = path_obs + '/daily_regression_stn.npz'\n",
    "file_corrmerge_stn = [''] * len(vars)\n",
    "for i in range(len(vars)):\n",
    "    file_corrmerge_stn[i] = path_bac + '/mergecorr_stn_' + vars[i] + '_GWRQM_' + weightmode + '.npz'\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# basic processing\n",
    "mask = io.loadmat(file_mask)\n",
    "mask = mask['DEM']\n",
    "mask[~np.isnan(mask)] = 1  # 1: valid pixels\n",
    "nrows, ncols = np.shape(mask)\n",
    "\n",
    "# date\n",
    "date_list, date_number = m_DateList(1979, 2018, 'ByYear')\n",
    "\n",
    "# stninfo\n",
    "stnID, stninfo = au.readstnlist(FileStnInfo)\n",
    "nstn = len(stnID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OI merge at stations: prcp\n"
     ]
    }
   ],
   "source": [
    "for v in range(1):\n",
    "    print('OI merge at stations:', vars[v])\n",
    "    filemerge_stn = path_oimerge + '/OImerge_stn_GWRQMBMA_' + vars[v] + '.npz'\n",
    "#     if os.path.isfile(filemerge_stn):\n",
    "#         continue\n",
    "\n",
    "    # load station original observations\n",
    "    datatemp = np.load(gmet_stndatafile)\n",
    "    observation_stn = datatemp[vars[v]+'_stn']\n",
    "\n",
    "    # load station regression estimates (obs)\n",
    "    datatemp = np.load(file_regression_stn)\n",
    "    regression_stn = datatemp[vars[v]]\n",
    "    del datatemp\n",
    "\n",
    "    # load corrected/merged reanalysis data at all station points (those are totally independent with station observations)\n",
    "    # and find the best choice\n",
    "    datatemp = np.load(file_corrmerge_stn[v])\n",
    "    reamerge_stn_all = datatemp['reamerge_stn']\n",
    "    reacorr_stn_all = datatemp['reacorr_stn']\n",
    "    reanum, nstn, ntimes = np.shape(reacorr_stn_all)\n",
    "    del datatemp\n",
    "    reafinal_stn = np.nan * np.zeros([nstn, ntimes], dtype=np.float32)\n",
    "    for m in range(12):\n",
    "        indm =  (date_number['mm'] == m + 1)\n",
    "        rearmse = np.zeros([nstn, reanum + 1])\n",
    "        rearmse[:, 0] = calmetric(reamerge_stn_all[:, indm], observation_stn[:, indm], metname='RMSE')\n",
    "        for i in range(reanum):\n",
    "            rearmse[:, i + 1] = calmetric(reacorr_stn_all[i, :, indm].T, observation_stn[:, indm], metname='RMSE')\n",
    "        bestchoice = np.argmin(rearmse, axis=1)\n",
    "        for i in range(nstn):\n",
    "            if bestchoice[i] > 0:\n",
    "                reafinal_stn[i, indm] = reacorr_stn_all[bestchoice[i] - 1, i, indm]\n",
    "            else:\n",
    "                reafinal_stn[i, indm] = reamerge_stn_all[i, indm]\n",
    "\n",
    "    # load near station information\n",
    "    datatemp = np.load(near_file_GMET)\n",
    "    if vars[v] == 'prcp':\n",
    "        near_loc = datatemp['near_stn_prcpLoc']\n",
    "        near_weight = datatemp['near_stn_prcpWeight']\n",
    "    else:\n",
    "        near_loc = datatemp['near_stn_tempLoc']\n",
    "        near_weight = datatemp['near_stn_tempWeight']\n",
    "    del datatemp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # start OI merging\n",
    "    oimerge_stn = np.zeros([nstn, ntimes])\n",
    "    for m in range(12):\n",
    "#         print('month', m + 1)\n",
    "        indm = (date_number['mm'] > m + 1)\n",
    "        nday = sum(indm)\n",
    "\n",
    "        # use optimal interpolation to get OI-merged estimate at each station points\n",
    "        for i in range(4000,4001):\n",
    "#             if np.mod(i,2000)==0:\n",
    "#                 print('station',i,nstn)\n",
    "\n",
    "            if not np.mod(i, 5)==0:\n",
    "                continue\n",
    "\n",
    "            if np.isnan(observation_stn[i, 0]):\n",
    "                continue\n",
    "\n",
    "            near_loci = near_loc[i, :]\n",
    "            near_loci = near_loci[near_loci > -1]\n",
    "\n",
    "            b_tar = reafinal_stn[i, indm]\n",
    "            o_tar = regression_stn[i, indm]\n",
    "            b_near = reafinal_stn[near_loci,:][:, indm]\n",
    "            o_near = regression_stn[near_loci,:][:, indm]\n",
    "\n",
    "            tar_err_b = b_tar - observation_stn[i, indm]\n",
    "            near_err_b = b_near - observation_stn[near_loci,:][:, indm]\n",
    "            near_err_o = o_near - observation_stn[near_loci,:][:, indm]\n",
    "            weight = OImerge(tar_err_b[31:], near_err_b[:,31:], near_err_o[:,31:], eye_o=0)\n",
    "            if np.any(np.isnan(weight)) or np.any(abs(weight) > 2):\n",
    "                weight = near_weight[i, 0:len(near_loci)]\n",
    "                weight = weight / np.sum(weight)\n",
    "\n",
    "            diff = o_near - b_near\n",
    "            merge_est = b_tar.copy()\n",
    "            for id in range(nday):\n",
    "                merge_est[id] = merge_est[id] + np.dot(weight, diff[:, id])\n",
    "\n",
    "            oimerge_stn[i, indm] = merge_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62822921 1.21617925 2.6009481  5.28557121]\n",
      "[0.43289948 0.87695855 2.91936135 6.61388205]\n",
      "[0.64924751 1.19372947 2.57689691 5.06135172]\n"
     ]
    }
   ],
   "source": [
    "print(au.metric(observation_stn[i,366:],regression_stn[i,366:]))\n",
    "print(au.metric(observation_stn[i,366:],reafinal_stn[i,366:]))\n",
    "print(au.metric(observation_stn[i,366:],oimerge_stn[i,366:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62822921 1.21617925 2.6009481  5.28557121]\n",
      "[0.43289948 0.87695855 2.91936135 6.61388205]\n",
      "[0.65349947 1.20496713 2.57704736 5.0521345 ]\n"
     ]
    }
   ],
   "source": [
    "print(au.metric(observation_stn[i,366:],regression_stn[i,366:]))\n",
    "print(au.metric(observation_stn[i,366:],reafinal_stn[i,366:]))\n",
    "print(au.metric(observation_stn[i,366:],oimerge_stn[i,366:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
