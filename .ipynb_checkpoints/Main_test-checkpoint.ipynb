{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import auxiliary as au\n",
    "import regression as reg\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import io\n",
    "import os\n",
    "import sys\n",
    "\n",
    "########################################################################################################################\n",
    "# date_cal_start = int(sys.argv[1]) # yyyymmdd\n",
    "# date_cal_end = int(sys.argv[2])\n",
    "\n",
    "# 0. read/define configuration information\n",
    "\n",
    "# setting: start and end date\n",
    "# calculation start/end date:\n",
    "date_cal_start = 19790101  # yyyymmdd: start date\n",
    "date_cal_end = 19790131  # yyyymmdd: end date\n",
    "# station data (in PathStn) start/end date:\n",
    "date_stn_start = 19790101  # yyyymmdd: start date\n",
    "date_stn_end = 20181231  # yyyymmdd: end date\n",
    "\n",
    "# setting: paramters for lag correlation of tmean_stn_daily, and cross-correlation between prcp and trange_stn_daily\n",
    "windows = 1  # parameters for auto-cc t-p-cc calculation: 1 could be better than 31\n",
    "lag = 1\n",
    "\n",
    "# setting: searching nearby stations\n",
    "nearstn_min = 20  # nearby stations: minimum number\n",
    "nearstn_max = 30  # nearby stations: maximum number\n",
    "search_radius = 400  # km. only search stations within this radius even nearstn_max cannot be reached\n",
    "max_dist = 100  # max_distance in distance-based weight calculation\n",
    "\n",
    "# setting: parameters for transforming temp to approximate normal distribution\n",
    "trans_mode = 'none'  # box-cox or power-law or none\n",
    "trans_exp_daily = 4\n",
    "\n",
    "# setting: overwrite flags. -1:don't save files; 0: don't overwrite files; 1 is to overwrite existing files;\n",
    "ow_daily = 0\n",
    "ow_weight = 0\n",
    "ow_stn = 0\n",
    "\n",
    "# setting: output files\n",
    "datestr = str(date_cal_start) + '-' + str(date_cal_end)\n",
    "\n",
    "### Plato settings\n",
    "# FileStnInfo = '/home/gut428/GMET/eCAI_EMDNA/StnGridInfo/stnlist_whole.txt'  # station basic information (lists)\n",
    "# FileGridInfo = '/home/gut428/GMET/eCAI_EMDNA/StnGridInfo/gridinfo_whole.nc'  # study area information\n",
    "# PathStn = '/home/gut428/GMET/StnInput_daily'\n",
    "\n",
    "# FileStnData = '/home/gut428/GMET/PyGMETout/stndata_' + datestr + '.npz'\n",
    "# FileWeight = '/home/gut428/GMET/PyGMETout/weight.npz'\n",
    "# FileRegError_daily = '/home/gut428/GMET/PyGMETout/error_' + datestr + '.npz'  # regression error at station points\n",
    "# FileRegError_daily_corr = '/home/gut428/GMET/PyGMETout/error_rescorr' + datestr + '.npz'  # regression error after residual correction\n",
    "# FileRegression_daily = '/home/gut428/GMET/PyGMETout/output_' + datestr + '.npz'\n",
    "### Plato settings\n",
    "\n",
    "### Mac settings\n",
    "FileStnInfo = '/Users/localuser/GMET/pyGMET_NA/stnlist_whole.txt'  # station basic information (lists)\n",
    "FileGridInfo = '/Users/localuser/GMET/pyGMET_NA/gridinfo_whole.nc'  # study area information\n",
    "PathStn = '/Users/localuser/GMET/StnInput_daily'\n",
    "\n",
    "FileStnData = '/Users/localuser/Research/EMDNA/regression/stndata_' + datestr + '.npz'\n",
    "FileWeight = '/Users/localuser/Research/EMDNA/regression/weight_nearstn.npz'\n",
    "FileRegError_daily = '/Users/localuser/Research/EMDNA/regression/error_notrans_' + datestr + '.npz'  # regression error at station points\n",
    "FileRegError_daily_corr = '/Users/localuser/Research/EMDNA/regression/error_rescorr' + datestr + '.npz'\n",
    "FileRegression_daily = '/Users/localuser/Research/EMDNA/regression/output_' + datestr + '.npz'\n",
    "### Mac settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read study area basic information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/localuser/Github/PyGMET/auxiliary.py:13: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  data = np.genfromtxt(FileStnInfo, delimiter=',', dtype=None, skip_header=2)\n"
     ]
    }
   ],
   "source": [
    "# 1. basic information\n",
    "\n",
    "print('Read study area basic information')\n",
    "# station location and attribute information\n",
    "# stninfo: [ stations, 1/lat/lon/elev/slope_ns/slope_we ]\n",
    "stnID, stninfo = au.readstnlist(FileStnInfo)\n",
    "nstn = len(stnID)\n",
    "\n",
    "# time information\n",
    "if date_cal_start < date_stn_start:\n",
    "    sys.exit('The calculation period is earlier than the station period')\n",
    "if date_cal_end > date_stn_end:\n",
    "    sys.exit('The calculation period is later than the station period')\n",
    "\n",
    "date_cal_start2 = dt.datetime.strptime(str(date_cal_start), '%Y%m%d')\n",
    "date_cal_end2 = dt.datetime.strptime(str(date_cal_end), '%Y%m%d')\n",
    "ntimes = (date_cal_end2 - date_cal_start2).days + 1  # time steps to be processed\n",
    "\n",
    "date_stn_start2 = dt.datetime.strptime(str(date_stn_start), '%Y%m%d')\n",
    "loc_start = (date_cal_start2 - date_stn_start2).days  # start location in the netcdf file\n",
    "loc_end = loc_start + ntimes\n",
    "\n",
    "# seconds since 1970-1-1 0:0:0\n",
    "daydiff = (date_cal_start2 - dt.datetime(1970, 1, 1)).days\n",
    "seconds = (np.arange(ntimes) + daydiff) * 86400\n",
    "\n",
    "# datelist: yyyymmdd\n",
    "yyyymmdd = np.zeros(ntimes, dtype=int)\n",
    "for d in range(ntimes):\n",
    "    dated = date_cal_start2 + dt.timedelta(days=d)\n",
    "    yyyymmdd[d] = int(dated.strftime(\"%Y%m%d\"))\n",
    "yyyymm = np.floor(yyyymmdd / 100).astype(int)\n",
    "mm = np.floor(np.mod(yyyymmdd, 10000) / 100).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read study area basic information\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. basic information\n",
    "\n",
    "print('Read study area basic information')\n",
    "# station location and attribute information\n",
    "# stninfo: [ stations, 1/lat/lon/elev/slope_ns/slope_we ]\n",
    "stnID, stninfo = au.readstnlist(FileStnInfo)\n",
    "nstn = len(stnID)\n",
    "\n",
    "# time information\n",
    "if date_cal_start < date_stn_start:\n",
    "    sys.exit('The calculation period is earlier than the station period')\n",
    "if date_cal_end > date_stn_end:\n",
    "    sys.exit('The calculation period is later than the station period')\n",
    "\n",
    "date_cal_start2 = dt.datetime.strptime(str(date_cal_start), '%Y%m%d')\n",
    "date_cal_end2 = dt.datetime.strptime(str(date_cal_end), '%Y%m%d')\n",
    "ntimes = (date_cal_end2 - date_cal_start2).days + 1  # time steps to be processed\n",
    "\n",
    "date_stn_start2 = dt.datetime.strptime(str(date_stn_start), '%Y%m%d')\n",
    "loc_start = (date_cal_start2 - date_stn_start2).days  # start location in the netcdf file\n",
    "loc_end = loc_start + ntimes\n",
    "\n",
    "# seconds since 1970-1-1 0:0:0\n",
    "daydiff = (date_cal_start2 - dt.datetime(1970, 1, 1)).days\n",
    "seconds = (np.arange(ntimes) + daydiff) * 86400\n",
    "\n",
    "# datelist: yyyymmdd\n",
    "yyyymmdd = np.zeros(ntimes, dtype=int)\n",
    "for d in range(ntimes):\n",
    "    dated = date_cal_start2 + dt.timedelta(days=d)\n",
    "    yyyymmdd[d] = int(dated.strftime(\"%Y%m%d\"))\n",
    "yyyymm = np.floor(yyyymmdd / 100).astype(int)\n",
    "mm = np.floor(np.mod(yyyymmdd, 10000) / 100).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read study area basic information\n",
      "Read station precipitation and temperature data\n",
      "FileStnData exists. loading ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. read study area basic information\n",
    "print('Read study area basic information')\n",
    "ncfid = nc.Dataset(FileGridInfo)\n",
    "gridlat = ncfid.variables['latitude'][:].data\n",
    "gridlon = ncfid.variables['longitude'][:].data\n",
    "gridele = ncfid.variables['elev'][:].data\n",
    "gridgns = ncfid.variables['gradient_n_s'][:].data\n",
    "gridgwe = ncfid.variables['gradient_w_e'][:].data\n",
    "mask = ncfid.variables['mask'][:].data  # 1: grids to be considered; the other values: invalid grids\n",
    "ncfid.close()\n",
    "\n",
    "nrows, ncols = np.shape(gridlat)\n",
    "gridinfo = np.zeros([nrows, ncols, 6])\n",
    "gridinfo[:, :, 0] = 1\n",
    "gridinfo[:, :, 1] = gridlat\n",
    "gridinfo[:, :, 2] = gridlon\n",
    "gridinfo[:, :, 3] = gridele\n",
    "gridinfo[:, :, 4] = gridgns\n",
    "gridinfo[:, :, 5] = gridgwe\n",
    "del gridlat, gridlon, gridele, gridgns, gridgwe\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# 3. read data (prcp, tmin, tmax) from station files\n",
    "print('Read station precipitation and temperature data')\n",
    "if os.path.isfile(FileStnData) and ow_stn != 1:\n",
    "    print('FileStnData exists. loading ...')\n",
    "    with np.load(FileStnData) as datatemp:\n",
    "        prcp_stn_daily = datatemp['prcp_stn_daily']\n",
    "        tmean_stn_daily = datatemp['tmean_stn_daily']\n",
    "        trange_stn_daily = datatemp['trange_stn_daily']\n",
    "        prcp_stn_climo = datatemp['prcp_stn_climo']\n",
    "        tmean_stn_climo = datatemp['tmean_stn_climo']\n",
    "        trange_stn_climo = datatemp['trange_stn_climo']\n",
    "        prcp_stn_anom = datatemp['prcp_stn_anom']\n",
    "        tmean_stn_anom = datatemp['tmean_stn_anom']\n",
    "        trange_stn_anom = datatemp['trange_stn_anom']\n",
    "else:\n",
    "    cai_mode = 0\n",
    "    prcp_stn_daily, tmean_stn_daily, trange_stn_daily, \\\n",
    "    prcp_stn_climo, tmean_stn_climo, trange_stn_climo, \\\n",
    "    prcp_stn_anom, tmean_stn_anom, trange_stn_anom \\\n",
    "        = au.read_station(PathStn, stnID, loc_start, loc_end, cai_mode, yyyymm)\n",
    "    np.savez_compressed(FileStnData,\n",
    "                        prcp_stn_daily=prcp_stn_daily, tmean_stn_daily=tmean_stn_daily, trange_stn_daily=trange_stn_daily)\n",
    "    del prcp_stn_climo, tmean_stn_climo, trange_stn_climo, prcp_stn_anom, tmean_stn_anom, trange_stn_anom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate correlation (auto_cc and t_p_cc)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.7/site-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tmean lag-1 daily autocorrelation:  0.6218259723411609\n",
      "Trange-prcp daily correlation:  -0.1348008479074349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/localuser/Github/PyGMET/auxiliary.py:186: RuntimeWarning: invalid value encountered in greater\n",
      "  auto_corr[abs(auto_corr) > 1] = np.nan\n",
      "/Users/localuser/Github/PyGMET/auxiliary.py:187: RuntimeWarning: invalid value encountered in greater\n",
      "  t_p_corr[abs(t_p_corr) > 1] = np.nan\n"
     ]
    }
   ],
   "source": [
    "# 4. calculate auto_corr and t_p_corr\n",
    "print('Calculate correlation (auto_cc and t_p_cc)')\n",
    "mean_autocorr_daily, mean_tp_corr_daily = au.cc_calculate(windows, lag, prcp_stn_daily, tmean_stn_daily,\n",
    "                                                          trange_stn_daily)\n",
    "print('Tmean lag-1 daily autocorrelation: ', mean_autocorr_daily)\n",
    "print('Trange-prcp daily correlation: ', mean_tp_corr_daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileWeight exists. loading ...\n"
     ]
    }
   ],
   "source": [
    "# 5. find neighboring stations and calculate distance-based weights\n",
    "if os.path.isfile(FileWeight) and ow_weight != 1:\n",
    "    print('FileWeight exists. loading ...')\n",
    "    with np.load(FileWeight) as datatemp:\n",
    "        near_grid_prcpLoc = datatemp['near_grid_prcpLoc']\n",
    "        near_grid_prcpWeight = datatemp['near_grid_prcpWeight']\n",
    "        near_grid_tempLoc = datatemp['near_grid_tempLoc']\n",
    "        near_grid_tempWeight = datatemp['near_grid_tempWeight']\n",
    "        near_stn_prcpLoc = datatemp['near_stn_prcpLoc']\n",
    "        near_stn_prcpWeight = datatemp['near_stn_prcpWeight']\n",
    "        near_stn_tempLoc = datatemp['near_stn_tempLoc']\n",
    "        near_stn_tempWeight = datatemp['near_stn_tempWeight']\n",
    "    del datatemp\n",
    "else:\n",
    "    near_grid_prcpLoc, near_grid_prcpDist, near_grid_prcpWeight, \\\n",
    "    near_grid_tempLoc, near_grid_tempDist, near_grid_tempWeight, \\\n",
    "    near_stn_prcpLoc, near_stn_prcpDist, near_stn_prcpWeight, \\\n",
    "    near_stn_tempLoc, near_stn_tempDist, near_stn_tempWeight \\\n",
    "        = au.station_weight(prcp_stn_daily, tmean_stn_daily, stninfo, gridinfo, mask,\n",
    "                            search_radius, nearstn_min, nearstn_max, max_dist)\n",
    "\n",
    "    # save data\n",
    "    np.savez_compressed(FileWeight, near_grid_prcpLoc=near_grid_prcpLoc, near_grid_prcpDist=near_grid_prcpDist,\n",
    "                        near_grid_prcpWeight=near_grid_prcpWeight, near_grid_tempLoc=near_grid_tempLoc,\n",
    "                        near_grid_tempDist=near_grid_tempDist, near_grid_tempWeight=near_grid_tempWeight,\n",
    "                        near_stn_prcpLoc=near_stn_prcpLoc, near_stn_prcpDist=near_stn_prcpDist,\n",
    "                        near_stn_prcpWeight=near_stn_prcpWeight, near_stn_tempLoc=near_stn_tempLoc,\n",
    "                        near_stn_tempDist=near_stn_tempDist, near_stn_tempWeight=near_stn_tempWeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate daily regression error at station points\n",
      "Current time: 0 Total times: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/localuser/Github/PyGMET/regression.py:165: RuntimeWarning: overflow encountered in exp\n",
      "  popgg = 1 / (1 + np.exp(zb))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time: 1 Total times: 31\n",
      "Current time: 2 Total times: 31\n",
      "Current time: 3 Total times: 31\n",
      "Current time: 4 Total times: 31\n",
      "Current time: 5 Total times: 31\n",
      "Current time: 6 Total times: 31\n",
      "Current time: 7 Total times: 31\n",
      "Current time: 8 Total times: 31\n",
      "Current time: 9 Total times: 31\n",
      "Current time: 10 Total times: 31\n",
      "Current time: 11 Total times: 31\n",
      "Current time: 12 Total times: 31\n",
      "Current time: 13 Total times: 31\n",
      "Current time: 14 Total times: 31\n",
      "Current time: 15 Total times: 31\n",
      "Current time: 16 Total times: 31\n",
      "Current time: 17 Total times: 31\n",
      "Current time: 18 Total times: 31\n",
      "Current time: 19 Total times: 31\n",
      "Current time: 20 Total times: 31\n",
      "Current time: 21 Total times: 31\n",
      "Current time: 22 Total times: 31\n",
      "Current time: 23 Total times: 31\n",
      "Current time: 24 Total times: 31\n",
      "Current time: 25 Total times: 31\n",
      "Current time: 26 Total times: 31\n",
      "Current time: 27 Total times: 31\n",
      "Current time: 28 Total times: 31\n",
      "Current time: 29 Total times: 31\n",
      "Current time: 30 Total times: 31\n"
     ]
    }
   ],
   "source": [
    "# 6.1 estimate regression error at station points\n",
    "if not os.path.isfile(FileRegError_daily) and ow_daily != 1:\n",
    "    print('FileRegError_daily exists. loading ...')\n",
    "    with np.load(FileRegError_daily) as datatemp:\n",
    "        pcp_err_stn_daily = datatemp['pcp_err_stn']\n",
    "        tmean_err_stn_daily = datatemp['tmean_err_stn']\n",
    "        trange_err_stn_daily = datatemp['trange_err_stn']\n",
    "    del datatemp\n",
    "else:\n",
    "    print('Estimate daily regression error at station points')\n",
    "    pcp_err_stn_daily, tmean_err_stn_daily, trange_err_stn_daily, pop_err_stn_daily = \\\n",
    "        reg.station_error(prcp_stn_daily, tmean_stn_daily, trange_stn_daily, stninfo, near_stn_prcpLoc,\n",
    "                          near_stn_prcpWeight, near_stn_tempLoc, near_stn_tempWeight, trans_exp_daily,\n",
    "                          trans_mode, nearstn_min)\n",
    "\n",
    "    pcp_reg_stn = pcp_err_stn_daily + prcp_stn_daily\n",
    "    tmean_reg_stn = tmean_err_stn_daily + tmean_stn_daily\n",
    "    trange_reg_stn = trange_err_stn_daily + trange_stn_daily\n",
    "\n",
    "    prcp_stn_daily[prcp_stn_daily>0] = 1\n",
    "    pop_reg_stn = pop_err_stn_daily + prcp_stn_daily\n",
    "\n",
    "    np.savez_compressed(FileRegError_daily, pcp_reg_stn=pcp_reg_stn, tmean_reg_stn=tmean_reg_stn,\n",
    "                        trange_reg_stn=trange_reg_stn, pop_reg_stn=pop_reg_stn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in greater\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y_pop = prcp_stn_daily.copy()\n",
    "y_pop[y_pop>0]=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
