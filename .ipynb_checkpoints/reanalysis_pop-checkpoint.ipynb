{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import regression as reg\n",
    "from scipy import io\n",
    "from auxiliary_merge import m_DateList\n",
    "import os, sys\n",
    "from bma_merge import bma\n",
    "from auxiliary_merge import extrapolation\n",
    "\n",
    "\n",
    "# read from inputs\n",
    "# time1 = int(sys.argv[1])\n",
    "# time2 = int(sys.argv[2])\n",
    "# print(time1,time2)\n",
    "\n",
    "prefix = ['ERA5_', 'MERRA2_', 'JRA55_']\n",
    "\n",
    "### Local Mac settings\n",
    "# input files/paths\n",
    "gmet_stnfile = '/Users/localuser/Research/EMDNA/basicinfo/stnlist_whole.txt'\n",
    "gmet_stndatafile = '/Users/localuser/Research/EMDNA/stndata_whole.npz'\n",
    "file_mask = './DEM/NA_DEM_010deg_trim.mat'\n",
    "near_file_GMET = '/Users/localuser/Research/EMDNA/regression/weight_nearstn.npz' # near station of stations/grids\n",
    "path_readowngrid = ['/Users/localuser/Research/EMDNA/downscale/ERA5',  # downscaled gridded data\n",
    "                    '/Users/localuser/Research/EMDNA/downscale/MERRA2',\n",
    "                    '/Users/localuser/Research/EMDNA/downscale/JRA55']\n",
    "file_readownstn = ['/Users/localuser/Research/EMDNA/downscale/ERA5_downto_stn_nearest.npz', # downscaled to stn points\n",
    "                   '/Users/localuser/Research/EMDNA/downscale/MERRA2_downto_stn_nearest.npz',\n",
    "                   '/Users/localuser/Research/EMDNA/downscale/JRA55_downto_stn_nearest.npz']\n",
    "\n",
    "# output files/paths (can also be used as inputs once generated)\n",
    "near_path = '/Users/localuser/Research/EMDNA/correction'  # path to save near station for each grid/cell\n",
    "path_ecdf = '/Users/localuser/Research/EMDNA/merge/ECDF'\n",
    "path_pop = '/Users/localuser/Research/EMDNA/pop'\n",
    "### Local Mac settings\n",
    "\n",
    "\n",
    "# ### Plato settings\n",
    "# gmet_stnfile = '/datastore/GLOBALWATER/CommonData/EMDNA/StnGridInfo/stnlist_whole.txt'\n",
    "# gmet_stndatafile = '/datastore/GLOBALWATER/CommonData/EMDNA/stndata_whole.npz'\n",
    "# file_mask = '/datastore/GLOBALWATER/CommonData/EMDNA/DEM/NA_DEM_010deg_trim.mat'\n",
    "# near_file_GMET = '/datastore/GLOBALWATER/CommonData/EMDNA/PyGMETout/weight.npz'\n",
    "# path_readowngrid = ['/datastore/GLOBALWATER/CommonData/EMDNA/ERA5_day_ds',  # downscaled gridded data\n",
    "#                    '/datastore/GLOBALWATER/CommonData/EMDNA/MERRA2_day_ds',\n",
    "#                    '/datastore/GLOBALWATER/CommonData/EMDNA/JRA55_day_ds']\n",
    "# file_readownstn = ['/datastore/GLOBALWATER/CommonData/EMDNA/ERA5_day_ds/ERA5_downto_stn_GWR.npz', # downscaled to stn points\n",
    "#                    '/datastore/GLOBALWATER/CommonData/EMDNA/MERRA2_day_ds/MERRA2_downto_stn_GWR.npz',\n",
    "#                    '/datastore/GLOBALWATER/CommonData/EMDNA/JRA55_day_ds/JRA55_downto_stn_GWR.npz']\n",
    "# near_path = '/home/gut428/ReanalysisCorrMerge'  # path to save near station for each grid/cell\n",
    "# path_ecdf = '/datastore/GLOBALWATER/CommonData/EMDNA/ReanalysisCorrMerge/ECDF'\n",
    "# path_pop = '/home/gut428/ReanalysisCorrMerge/pop'\n",
    "# file_popmerge_stn = '/home/gut428/ReanalysisCorrMerge/pop/bmamerge_pop_stn.npz'\n",
    "# ### Plato settings\n",
    "\n",
    "near_stnfile = near_path + '/near_stn_prcp.npz'\n",
    "near_gridfile = near_path + '/near_grid_prcp.npz'\n",
    "file_reapop_stn = path_pop + '/reanalysis_pop_stn.npz'\n",
    "file_popmerge_stn = path_pop + 'bmamerge_pop_stn.npz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start basic processing\n",
      "load downscaled reanalysis data at station points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:56: RuntimeWarning: invalid value encountered in less\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "\n",
    "# basic processing\n",
    "print('start basic processing')\n",
    "\n",
    "lontar = np.arange(-180 + 0.05, -50, 0.1)\n",
    "lattar = np.arange(85 - 0.05, 5, -0.1)\n",
    "# mask\n",
    "mask = io.loadmat(file_mask)\n",
    "mask = mask['DEM']\n",
    "mask[~np.isnan(mask)] = 1  # 1: valid pixels\n",
    "\n",
    "# meshed lat/lon of the target region\n",
    "reanum = len(file_readownstn)\n",
    "nrows, ncols = np.shape(mask)\n",
    "lontarm, lattarm = np.meshgrid(lontar, lattar)\n",
    "lontarm[np.isnan(mask)] = np.nan\n",
    "lattarm[np.isnan(mask)] = np.nan\n",
    "\n",
    "# date list\n",
    "date_list, date_number = m_DateList(1979, 2018, 'ByYear')\n",
    "\n",
    "# load observations for all stations\n",
    "datatemp = np.load(gmet_stndatafile)\n",
    "stndata = datatemp['prcp_stn']\n",
    "stnlle = datatemp['stn_lle']\n",
    "nstn, ntimes = np.shape(stndata)\n",
    "del datatemp\n",
    "\n",
    "# load near station information\n",
    "datatemp = np.load(near_file_GMET)\n",
    "near_loc_stn = datatemp['near_stn_prcpLoc']\n",
    "near_weight_stn = datatemp['near_stn_prcpWeight']\n",
    "near_dist_stn = datatemp['near_stn_prcpDist']\n",
    "near_loc_grid = datatemp['near_grid_prcpLoc']\n",
    "near_weight_grid = datatemp['near_grid_prcpWeight']\n",
    "near_dist_grid = datatemp['near_grid_prcpDist']\n",
    "near_loc_grid = np.flipud(near_loc_grid)\n",
    "near_weight_grid = np.flipud(near_weight_grid)\n",
    "near_dist_grid = np.flipud(near_dist_grid)\n",
    "\n",
    "# probability bins for QM\n",
    "binprob = 500\n",
    "ecdf_prob = np.arange(0, 1 + 1 / binprob, 1 / binprob)\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# load downscaled reanalysis at station points\n",
    "print('load downscaled reanalysis data at station points')\n",
    "readata_stn = np.nan * np.zeros([reanum, nstn, ntimes], dtype=np.float32)\n",
    "for rr in range(reanum):\n",
    "    dr = np.load(file_readownstn[rr])\n",
    "    temp = dr['prcp_readown']\n",
    "    readata_stn[rr, :, :] = temp\n",
    "    del dr, temp\n",
    "readata_stn[readata_stn < 0] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method-1: estimate pop using a univariate regression between station occurrence (0-1) and reanalysis precipitation\n",
    "# file_popt = path_pop + '/reapop_stn_' + str(time1) + '-' + str(time2) + '.npz'\n",
    "if os.path.isfile(file_reapop_stn):\n",
    "    datatemp = np.load(file_reapop_stn)\n",
    "    reapop_stn = datatemp['reapop_stn']\n",
    "    del datatemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate bma merging weights for pop\n",
      "month 0\n",
      "month 1\n",
      "month 2\n",
      "month 3\n",
      "month 4\n",
      "month 5\n",
      "month 6\n",
      "month 7\n",
      "month 8\n",
      "month 9\n",
      "month 10\n",
      "month 11\n"
     ]
    }
   ],
   "source": [
    "    print('estimate bma merging weights for pop')\n",
    "    bmaweight_stn = np.nan * np.zeros([12, nstn, reanum], dtype=np.float32)\n",
    "    for m in range(12):\n",
    "        print('month',m)\n",
    "        indm = date_number['mm'] == (m+1)\n",
    "        for i in range(nstn):\n",
    "            if np.isnan(stndata[i, 0]):\n",
    "                continue\n",
    "            rea = reapop_stn[:, i, indm].T\n",
    "            obs = stndata[i, indm].copy()\n",
    "            obs[obs > 0] = 1\n",
    "            weight, sigma, sigma_s = bma(rea, obs)\n",
    "            bmaweight_stn[m, i, :] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "    mergepop_stn = np.nan * np.zeros([nstn, ntimes], dtype=np.float32)\n",
    "    for i in range(nstn):\n",
    "        if np.mod(i,5000)==0:\n",
    "            print(i)\n",
    "        if np.isnan(stndata[i, 0]):\n",
    "            continue\n",
    "        nearloc = near_loc_stn[i, :]\n",
    "        nearweight = near_weight_stn[i, :]\n",
    "        nearweight = nearweight[nearloc > -1]\n",
    "        nearweight = nearweight / np.sum(nearweight)\n",
    "        nearloc = nearloc[nearloc > -1]\n",
    "        nearweight = np.tile(nearweight,[reanum, 1]).T\n",
    "\n",
    "        # get bma weight from nearby stations\n",
    "        weight_i = np.zeros([12, reanum])\n",
    "        for m in range(12):\n",
    "            weight_im_near = bmaweight_stn[m, nearloc, :]\n",
    "            weight_i[m, :] = np.sum(weight_im_near * nearweight, axis=0)\n",
    "\n",
    "        # merging at the target station\n",
    "        reapop_merge_i = np.zeros(ntimes)\n",
    "        for m in range(12):\n",
    "            indm = date_number['mm'] == (m + 1)\n",
    "            reapop_stn_im = reapop_stn[:, i, indm]\n",
    "            weight_im = np.tile(weight_i[m, :], [np.sum(indm), 1]).T\n",
    "            weight_im[np.isnan(reapop_stn_im)] = np.nan\n",
    "            reapop_merge_i[indm] = np.nansum(reapop_stn_im * weight_im, axis=0) / np.nansum(weight_im, axis=0)\n",
    "\n",
    "        mergepop_stn[i, :] = reapop_merge_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # interpolate weights to grids\n",
    "    bmaweight_grid  = np.nan * np.zeros([12, reanum, nrows, ncols], dtype=np.float32)\n",
    "    for m in range(12):\n",
    "        for rr in range(reanum):\n",
    "            bmaweight_grid[m, rr, :, :] = extrapolation(bmaweight_stn[m, :, rr], near_loc_grid, near_dist_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(file_popmerge_stn, bmaweight_stn=bmaweight_stn, bmaweight_grid=bmaweight_grid, mergepop_stn=mergepop_stn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='/Users/localuser/Downloads/weight.npz'\n",
    "datatemp = np.load(file)\n",
    "near_loc_grid2 = datatemp['near_grid_prcpLoc']\n",
    "near_weight_grid2 = datatemp['near_grid_prcpWeight']\n",
    "near_dist_grid2 = datatemp['near_grid_prcpDist']\n",
    "near_loc_grid2 = np.flipud(near_loc_grid2)\n",
    "near_weight_grid2 = np.flipud(near_weight_grid2)\n",
    "near_dist_grid2 = np.flipud(near_dist_grid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='/Users/localuser/Downloads/weight.npz'\n",
    "datatemp = np.load(file)\n",
    "near_loc_stn2 = datatemp['near_stn_prcpLoc']\n",
    "near_weight_stn2 = datatemp['near_stn_prcpWeight']\n",
    "near_dist_stn2 = datatemp['near_stn_prcpDist']\n",
    "near_loc_grid2 = datatemp['near_grid_prcpLoc']\n",
    "near_weight_grid2 = datatemp['near_grid_prcpWeight']\n",
    "near_dist_grid2 = datatemp['near_grid_prcpDist']\n",
    "\n",
    "datatemp = np.load(near_file_GMET)\n",
    "near_loc_stn = datatemp['near_stn_prcpLoc']\n",
    "near_weight_stn = datatemp['near_stn_prcpWeight']\n",
    "near_dist_stn = datatemp['near_stn_prcpDist']\n",
    "near_loc_grid = datatemp['near_grid_prcpLoc']\n",
    "near_weight_grid = datatemp['near_grid_prcpWeight']\n",
    "near_dist_grid = datatemp['near_grid_prcpDist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='/Users/localuser/Downloads/weight.npz'\n",
    "datatemp = np.load(file)\n",
    "near_loc_stn2 = datatemp['near_stn_tempLoc']\n",
    "near_weight_stn2 = datatemp['near_stn_tempWeight']\n",
    "near_dist_stn2 = datatemp['near_stn_tempDist']\n",
    "near_loc_grid2 = datatemp['near_grid_tempLoc']\n",
    "near_weight_grid2 = datatemp['near_grid_tempWeight']\n",
    "near_dist_grid2 = datatemp['near_grid_tempDist']\n",
    "\n",
    "datatemp = np.load(near_file_GMET)\n",
    "near_loc_stn = datatemp['near_stn_tempLoc']\n",
    "near_weight_stn = datatemp['near_stn_tempWeight']\n",
    "near_dist_stn = datatemp['near_stn_tempDist']\n",
    "near_loc_grid = datatemp['near_grid_tempLoc']\n",
    "near_weight_grid = datatemp['near_grid_tempWeight']\n",
    "near_dist_grid = datatemp['near_grid_tempDist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4457\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(near_loc_stn2!=near_loc_stn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  4,   4,   4, ..., 766, 766, 766]),\n",
       " array([929, 929, 929, ..., 998, 999, 999]),\n",
       " array([20, 21, 22, ..., 21, 20, 21]))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff=near_dist_grid2-near_dist_grid\n",
    "diff[abs(diff)<0.1]=0\n",
    "np.where(diff!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
      " -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
      " -999. -999. -999. -999. -999. -999.]\n",
      "[-999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
      " -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
      " -999. -999. -999. -999. -999. -999.]\n"
     ]
    }
   ],
   "source": [
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "        file_reapop = path_pop + '/rea_pop_' + str(y * 100 + m + 1) + '.npz'\n",
    "        file_bmapop = path_pop + '/bmamerge_pop_' + str(y * 100 + m + 1) + '.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # date processing\n",
    "        indmy = (date_number['yyyy'] == y) & (date_number['mm'] == m + 1)\n",
    "        mmdays = np.sum(indmy)\n",
    "\n",
    "        # read raw gridded reanalysis data\n",
    "        readata_raw = np.nan * np.zeros([reanum, nrows, ncols, mmdays], dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "        for rr in range(reanum):\n",
    "            if not (prefix[rr] == 'MERRA2_' and y == 1979):\n",
    "                filer = path_readowngrid[rr] + '/' + prefix[rr] + 'ds_prcp_' + str(y*100 +m+1) + '.npz'\n",
    "                d = np.load(filer)\n",
    "                readata_raw[rr, :, :, :] = d['data']\n",
    "                del d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 800\n",
      "1 800\n",
      "2 800\n",
      "3 800\n",
      "4 800\n",
      "5 800\n",
      "6 800\n",
      "7 800\n",
      "8 800\n",
      "9 800\n",
      "10 800\n",
      "11 800\n",
      "12 800\n",
      "13 800\n",
      "14 800\n",
      "15 800\n",
      "16 800\n",
      "17 800\n",
      "18 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in less\n",
      "/Users/localuser/Github/PyGMET/regression.py:44: RuntimeWarning: invalid value encountered in greater\n",
      "  if np.any(xb > 50):\n",
      "/Users/localuser/Github/PyGMET/regression.py:50: RuntimeWarning: invalid value encountered in greater\n",
      "  if np.any(p > 0.9999):\n",
      "/usr/local/lib/python3.7/site-packages/numpy/linalg/linalg.py:2125: RuntimeWarning: invalid value encountered in det\n",
      "  r = _umath_linalg.det(a, signature=signature)\n",
      "/Users/localuser/Github/PyGMET/regression.py:62: RuntimeWarning: invalid value encountered in greater\n",
      "  if np.any(np.abs(bn) > 1e-4):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 800\n",
      "20 800\n",
      "21 800\n",
      "22 800\n",
      "23 800\n",
      "24 800\n",
      "25 800\n",
      "26 800\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-a696b6b8488e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0mtx_red\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_red\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0mtwx_red\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx_red\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_pcp_red\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_red\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwx_red\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpstn_near\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                         \u001b[0mreapop_grid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnearweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpstn_near\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/PyGMET/regression.py\u001b[0m in \u001b[0;36mlogistic_regression\u001b[0;34m(x, tx, yp)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnstn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnstn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# diagonal variance matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnstn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mxv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "            reapop_grid = np.nan * np.zeros([reanum, nrows, ncols, mmdays], dtype=np.float32)\n",
    "            for r in range(nrows):\n",
    "                print(r, nrows)\n",
    "                for c in range(ncols):\n",
    "                    if np.isnan(mask[r, c]):\n",
    "                        continue\n",
    "                    nearloc = near_loc_grid[r, c, :]\n",
    "                    neardist = near_dist_grid[r, c, :]\n",
    "                    nearweight = near_weight_grid[r, c, :]\n",
    "                    neardist = neardist[nearloc > -1]\n",
    "                    nearweight = nearweight[nearloc > -1]\n",
    "                    nearweight = nearweight / np.sum(nearweight)\n",
    "                    nearloc = nearloc[nearloc > -1]\n",
    "\n",
    "                    nstn_prcp = len(nearloc)\n",
    "                    w_pcp_red = np.zeros([nstn_prcp, nstn_prcp])\n",
    "                    for i in range(nstn_prcp):\n",
    "                        w_pcp_red[i, i] = nearweight[i]  # eye matrix: stn weight in one-one lien\n",
    "\n",
    "                    x_red = np.ones([nstn_prcp, 2])\n",
    "                    for rr in range(reanum):\n",
    "                        for tt in range(mmdays):\n",
    "                            prea_tar = readata_raw[rr, r, c, tt]\n",
    "                            prea_near = readata_stn[rr, nearloc, tt]\n",
    "                            pstn_near = stndata[nearloc, tt]\n",
    "                            pstn_near[pstn_near > 0] = 1\n",
    "\n",
    "                            # logistic regression\n",
    "                            if np.all(pstn_near == 1):\n",
    "                                reapop_grid[rr, r, c, tt] = 1\n",
    "                            elif np.all(pstn_near == 0) or np.all(prea_near < 0.01):\n",
    "                                reapop_grid[rr, r, c, tt] = 0\n",
    "                            else:\n",
    "                                x_red[:, 1] = prea_near\n",
    "                                tx_red = np.transpose(x_red)\n",
    "                                twx_red = np.matmul(tx_red, w_pcp_red)\n",
    "                                b = reg.logistic_regression(x_red, twx_red, pstn_near)\n",
    "                                if np.all(b == 0) or np.any(np.isnan(b)):\n",
    "                                    reapop_grid[rr, r, c, tt] = np.dot(nearweight, pstn_near)\n",
    "                                else:\n",
    "                                    zb = - np.dot(np.array([1, prea_tar]), b)\n",
    "                                    reapop_grid[rr, r, c, tt] = 1 / (1 + np.exp(zb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in greater\n",
      "  \n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "            # initialization\n",
    "            bma_data = np.nan * np.zeros([nrows, ncols, mmdays], dtype=np.float32)\n",
    "\n",
    "            # (1) estimate the error of corrected data by interpolating stations\n",
    "            obs = stndata[:, indmy].copy()\n",
    "            obs[obs>0]=1\n",
    "            bma_error = extrapolation(mergepop_stn[:, indmy] - obs, near_loc_grid, near_dist_grid)\n",
    "\n",
    "            # (2) estimate the value of merged data\n",
    "            reamerge_weight_gridm = bmaweight_grid[m, :, :, :].copy()\n",
    "            for i in range(mmdays):\n",
    "                datai = reapop_grid[:, :, :, i]\n",
    "                weighti = reamerge_weight_gridm.copy()\n",
    "                weighti[np.isnan(datai)] = np.nan\n",
    "                bma_data[:, :, i] = np.nansum(weighti * datai, axis=0) / np.nansum(weighti, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
